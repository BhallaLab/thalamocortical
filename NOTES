-*- mode: org; fill-column: 78 -*-
#+STARTUP: lognotedone
#+TODO: TODO(t) WAIT(w@/!) | DONE(d@/!) CANCELED(c@)
* Converting Kahp and Kc
   I_K(AHP) is calculated like this:
   I_K(AHP) = Gbar*m*(V-Ek)
   where m is the activation constant calculated from:

	m' = alpha * ( 1 - m ) - beta * m 
   
	if( chi < 100 ) {
		alpha = chi * 1e-4
	}else{
		alpha = 0.01
	}
	beta = 0.01

   where chi is Ca2+ concentration in mM. The rates alpha and beta are in
   ms^-1
   
   So we created an HHChannel KAHP.  Since the channel activation is Ca+2
   concentration dependent, we have to use the zGate, which calculates the
   activation parameter from incoming concentration message rather than the
   voltage message. So we keep the Xpower and Ypower at 0 but change Zpower
   to 1. This creates an HHGate named "zGate" under the channel. Now we assume
   that the Ca2+ concentration remains in the range 0 - 1000.00 Mol/m^3 (= mM
   ) all the time. So we create the look-up tables in the HHgate with xmin =
   0.0, xmax = 1000.0, xdivs = 3000 ( we want the interpolation table to have
   3001 division).
   Now we calculate the A and B table entries using the formula coded above:
   ( we have multiplied by 1000 to convert ms to s )

   A = alpha = chi*1e-1 , when chi < 100

		10.0 , otherwise

   B = alpha + beta = chi*1e-1 + 10 , when chi < 100

			20 , otherwise.


   We connect the CaConc object "caConc" to this channel:

   caConc.connect("concSrc", kAHP, "concen")
  
  that is, the "concSrc" message-source from caConc is connected to the
  "concen" message-destination of the kAHP channel.
  
  We further tell the kAHP channel to calculate the conductance using
  concentration rather than compartement voltage by:

  kAHP.useConcentration = True



  The K(C) channel is somewhat different. The K(C) current is calculated as:
  
	if( 0.004(1/mM) * chi < 1 ) {
		iktmp =  m * 0.004(1/mM) * chi * ( v - ek ) 
		gamma = 0.004 * chi
	}else{
		iktmp =  m * ( v - ek )
	        gamma = 1.0
	}
	df = v-ek
	ik = gbar*iktmp


    here m is a regular activation variable and independent of [Ca2+]. 
    To plug in the [Ca+2] we use the zGate again: 

    But now we do not have any rate constants alpha and beta and no
    integration is needed for the zGate. We tell the channel to do this by:

    kC.instant = 4 

    now, for the zGate parameter is calculated as A/B instead of solving the
    first order rate equation. Let us call this instantaneous value.

    The first, second and third least significant bit of the "instant" field,
    if set, avoids the integration for x, y and z gate respectively. For
    example, if we set kC.instant = 1, only Y and Z gate and not the X gate
    parameters will be calculated by solving the rate equation. If we set
    kC.instant = 2, Y gate parameter will have instantaneous value. 
    kC.instant = 3 (011)binary: only X and Y gate give instantaneous values
    kC.instant = 5 (101)binary: only X and Z gate give instantaneous values
    kC.instant = 6 (110)binary: Y and Z gate give instantaneous values
    kC.instant = 7 (111)binary: all three gates give instantaneous values

    and so on.

    Since the conductance multiplier is calculated as A/B here, we set B = 1.0 and 

    A = 0.004*chi , when chi < 250,
	1.0 ,otherwise.

	The range of chi and the number of divisions is same as kAHP.

* <2008-03-11 Tue> Completed TCR cell.
  Getting funny timing results for cell creation. For large number of cells,
  creating the cells from scratch is faster than using deepcopy in
  moose. This happens for as few as 10 cells.

  Working on Spiny Stellates. for NaP, neuron model has a separate channel
  mechanism.

* <2008-03-12 Wed> Copy construction for TCR too slow
  Noticable difference in making multiple copies of TCR cells. For creating a
  cell from scratch, TCR takes much less time(~4s) than Spiny
  Stellate(~8s). But when making 10 copies, TCR takes ~20s while SS takes
  ~3s. 
* <2008-03-18 Tue> Testing the channels.
  The sample compartments are not behaving properly. Going into checking each
  channel type. Compartment with NaF channel only does not behave like that
  in squid. The compartment passive properties influence the behaviour.
  
* <2008-03-20 Thu> Upi suggested a check on input impedance
  Vm stabilizes at around -50mV for 1pA injection current.  Rin = 50e9 Ohm
  The plot is in: [[file:VmSS_20080320.png][Vm plot]] The plot looks like a series of backslashes. What
  is wrong? Not passive properties!
* <2008-03-21 Fri> Redoing from scratch incrementally.
  traub_incr.py is the file in which I am trying to incrementally test and
  develop the model. Funny behaviour. NaF.py has an identical compartment
  with NaFGluta channel. But the Vm for the traub_incr remains at 0.
* <2008-03-25 Tue> Found the problem source
  Whenever something is not directly given to useClock() function, it screws
  up.  In the flat script (flat_naf.py) I was giving useClock(0,
  "/soma,/soma/#") In object oriented version (naf.py) I was giving
  useClock(0,"/model/#") where model is the container for soma. Looks like
  /model/soma/naf was not getting the clock ticks properly.

* <2008-04-01 Tue> Resolved table dump problem
  Have been groping around for zero channel current in refactored code. It
  turns out to be a problem with how to dump table object into a file. I was
  passing "-mode xy" as parameter to tab2file assuming it will put the x
  values also. But this screws up and all y values are saved as 0.
* <2008-04-03 Thu> Partly working
  genesis and moose output are identical. pymoose version was slightly
  off. One of the reasons turns out to be difference in nap definition in
  genesis script. fixed.  first tried with NaF, NaP, KA, KDR - data in
  xxx.plot.multi then added K2 - data in xxx.plot.multi.k2 then added KAR -
  everythin screwed up - KAR taking over all types of channels and the nice
  spikies are replaced by an ugly single spike typical of KAR.

  This IS VOODOOOOOOOOOOOOOOOOO. After a break, rerunning the stuff gives
  nice result. Earlier an independent kar.g was giving different result from
  the kachannle.g implementation. Now they are identical.
* <2008-04-08 Tue> Finally done with KC
  KC channel was giving a terrible headache - although everything seemed to
  be set properly, its Ik/ Gk were remaining at zero. moving the setting of
  field instant to INSTANTZ before creating the Z table solved it. VOODOO.

  Still the currents in KC and KAHP seem ridiculusly small of the order of
  10^-22, Am I making some mistake in units of Z table?

* <2008-04-09 Wed> Ca conc - not understanding
  Put scale factor = 5.6e-6 as in genesis model for Traub 91. KAHP and KC
  currents were still negligible ( ~ 10^15 A ). Traub 94 mentioned 1000 fold
  mistake in it, so changing to 5.6e-3 helped. The thickness of shell was 0.2
  microns. B = scale/(Ad). It is of ~10^12 now - matching the prototype CA3
  in traub94 in genesis. But now [Ca] is 3.6 mM.

  Running same thing on moose - different results - most entries for kc
  current are 0. The nonzero ones are very small. Though for the first part
  the current spikes are coincident.

* <2008-04-10 Thu> Figuring out Ca dependent channels.
  still there is no effect of the Ca dependent channels on the vm plot. These
  are in 10^-12 range now. Several other currents seem to be negligible
  compared to naf and ka.
  the orders of the currents are:
	cal  ~ 10^-11		(+ -)
	km   ~ 10^-11		(- /)
	ar   ~ 10^-11		(- \)
	cat  ~ 10^-12		(+ /)
	kc   ~ 10^-12 - 10^-11	(- /)
	kahp ~ 10^-13 - 10^-12	(- /)
	k2   ~ 10^-12		(- -)
	ar   ~ 10^-12 - 10^-11	(- \)
	nap  ~ 10^-10           (+ -)
	naf  ~ 10^-9 - 10^-10   (+ -)
	ka   ~ 10^-9		(- /)

  SUCCESS!  finally managed to match both genesis and moose output: the
  problem was obviously in Ca+2 dependent channels. The field
  useConcentration is 0 by default in MOOSE even if we set Zpower to 1. That
  is why kahp and kc were not behaving. Also, CaConc object did not have the
  genesis compatible message field for incoming Ca+2 current. Had to add in
  MOOSE sourcecode.
* <2008-04-11 Fri> PyMoose and genesis matching nicely.

* <2008-04-14 Mon> ss.g - implemented spiney stellate - but no spike is coming up. 
   The single compartment simulation in ss.g matchess well with the
   runmultichan.g with single compartment having ss parameters.
 
* <2008-11-10 Mon 17:29> Restarting work on the model
  Up to last version the MOOSE and PyMOOSE models were not matching. Recently
  discovered that channels in bulbchan needed two reset() calls in pymoose in
  order to function properly.

  According to discussion with Upi today, the reset() method is there for
  backward compatibility, we need to separate out resched and reinit.
* <2008-11-11 Tue 11:54> Everything is flat
  Have been searching for the starting point. pymoose/trbtest.py was the
  script for creating a single compartment with all the channels in it. But
  now all the plots are flat. May be due to the reset bug.

  Added an extra reset - but no improvement.

  All seems to be broken - even the single compartment with single channel has
  only flat line Ik, Vm. The output file has only two 0 entries. Looks like
  Table is not getting input.

  The error was because I had removed 'stepmode' from PyMOOSE Table and now
  everything must be camelCase ( stepMode ) - after replacing stepmode with
  stepMode, ar.py works.

  trbtest.py also works.

* <2008-11-11 Tue 14:40> Get the genesis version up
  Trying to run the MOOSE version

  The genesis output is somewhat decent, but when I run the same file with
  MOOSE, it looks like just the output of an rc circuit. The channel outputs
  are also not appearing. By the way I implemented arglist command in MOOSE so
  that the script runs on both MOOSE and GENESIS.

* <2008-11-11 Tue 20:58> Found the original
  Just recovered the subversion copy of traub2005 from chikki. Current
  directory will be backed up was a tbz archive with today's date. Will
  compare with svn version and this one.
* <2008-11-14 Fri 17:38> Comparing genesis and MOOSE
  I passed genesis and moose versions through ediff. The only significant
  difference seems to be in setclock. Also, there are differences in ss.g
  which I am currently not using.
* <2008-11-14 Fri 23:10> Matching GENESIS and MOOSE
  GENESIS and MOOSE can now run the same script and the outputs are
  matching. But I have a feeling that this was so before. The outputs fork off
  when we use a multicompartmental cell. Upi had warned about symcompartment
  before.

  Now I am trying to make sure the PyMOOSE script also matches the output. It
  is kind of pain to verify the compartment connectivity. I don't know if a
  visual editor might help. May need to write GUI for myself. Or should I wait
  for Neuroconstruct or something becoming our GUI?
* <2008-11-27 Thu 00:17> Compare MOOSE and PyMOOSE
  Till now even for a single compartment with multiple channels the pymoose
  and moose outputs are varying. I just checked all the biophysical properties
  of the compartmen and all the channels in the two simulations, but they are
  IDENTICAL. So the whole thing seems to be very shady.

  Realized that the INJECTION was 1e-11 for PyMOOSE and 1e-13 for
  MOOSE/GENESIS. But even after correcting, the ouputs don't match. While
  MOOSE simulation shows a little discontinuity at the instant of current
  injection start, the PyMOOSE does not show any effect of the sudden
  injection current change.

  Feel that it would have been far better if we could compare them
  programmatically - what if the all object paths were identical and we could
  run the MOOSE simulation inside PyMOOSE and compare the states after every
  single step.

 * <2008-11-27 Thu 02:12> Lots of Dots 
   I noticed a lot of dot in the output when I run with pulsegen instead of
   explicitly setting inject. When investigating it, I realized the addmsg for
   pulsegen and compartment was failing in PyMOOSE because of a typo in the
   script. But even after correcting that the dots are there. Looks like one
   dot is printed for each step. Don't understand why.

   Now the MOOSE and PyMOOSE outputs are somewhat closer. Within 1500 steps
   (0.15 s) the number of spikes is same but pymoose output has slightly lower
   frequencey. The last spike is 0.004 s delayed in PyMOOSE.

* <2008-11-29 Sat 01:51> Stuck
  What is a better way to verify the two versions? How to match things piece
  by piece?
  
  I was thinking of using readcell to share some more space of the two
  versions - but that breaks GENESIS compatibility.

  Perhaps run MOOSE code inside pymoose.

  Use one container for the PyMOOSE model and one for MOOSE. Then replicate
  the same structure in both systems and see if they are identical.

  Design it well - that is the first step.

  May be start it from scratch.

* <2008-11-29 Sat 02:08> Restarting 
  Now I am going to move evrything from the cortical_network/traub2005 to
  here - checking each implementation and cleaning it up.

* TODO Document what I am doing. Keep track of the files.
  :PROPERTIES:
  :ID:       f7cd9d0b-e7c3-495f-a5ee-8410b912ccee
  :END:
* TODO Clean up trbutil.py and utility.g with verification in mind.
* <2008-12-02 Tue 23:01> Organizing tests
  Created file trb_tests.g. This file will contain all the tests as I build
  the simulation incrementally.  The test parameters will be common for single
  compartment. These variables are prefixed TEST. The RA, RM and CM are
  specific values.  I implemented a passive single compartment test to start
  with.

* <2008-12-03 Wed 00:04> Implemeting the PyMOOSE tests
  Started with replicating the passive single compartment in pymoose
  (trb_tests.py). In order to compare the whole model tree, I feel the need of
  comparison operator in Id.
  
  For the time being I'll go for sorting based on path.

* <2008-12-03 Wed 01:53> Single passive compartment test
  In the trb_tests.py I added a test to compare whole moose subtrees. I load
  the MOOSE model using loadG and construct the PyMOOSE model inside a
  class. The two are matching within floating point error limit 0.001.

* <2008-12-03 Wed 20:53> Multiple channels
  When going to add test for multiple channels I realized that the tests could
  be organized in a better way using a class hierarchy. This re-organization
  took up a lot of time and coding. But I feel this will reduce a lot of work
  as the code becomes more complex.
  Right now I am trying a single compartment with NaF and KDR channels only.
  - not working. output same as passive compartment. - I had forgotten to set
    Gbar for the channels.
* <2008-12-04 Thu 22:00> Multiple channels implemented
  Managed to simulate a single compartment with NaF and KDR channels on MOOSE
  and GENESIS  and while the MOOSE and GENESIS outputs are identical, they do
  not match pymoose output.
  The divergence is similar as earlier version - the spikes gradually go out
  of sync. According to Upi this indicates a mismatch in passive
  properties. Will do a field by field comparison using Python.

* <2008-12-04 Thu 22:23> Field by field comparison
  Just did a test case with field by field comparison of channels and
  compartments and it could not find any discrepancy between the pymoose model
  and the moose model in terms of field values.

  IS IT A BUG IN PYMOOSE? DID SOME OF THE BIOPHYSICAL OBJECTS CHANGE BEHAVIOUR
  WITHOUT PYMOOSE BEING UPDATED?

* <2008-12-05 Fri 01:16> FOUND THE BUG!
  At last!!! I was getting same gradual deviation of PyMOOSE and MOOSE
  Vm even with just NaF and KDR channels. 
  After confirming that all other fields were identical within 1 in 1000
  error, I set out to compare the individual gate tables, manually dumping the
  tables after running the comparison test case in PyMoose
  (MOOSEPySingleCompMultiChannelTestCase). And voila, the kdr channel's
  xGate/A tables were slightly different. When I looked into the code I
  realized that there is another variant of KDR channel for fast spiking
  neurons. The equation for Tau_m is identical for both, but the equations for
  m_inf vary slightly in terms of the constants ( 27e-3 instead of 29.5e-3 and
  11.5e-3 instead of 10e-3 ). And that was the culprit!!

* <2008-12-05 Fri 13:53> Reading Traub model
  I am verifying my code by checking out the fortran code and it looks
  cool. They have added all the conductances for the same ion and then
  calculated the overall ionic current. In MOOSE we don't have this
  facility. May be we can use this technique in solver.
  n a second thought, this is not such a big deal. Because, still we have to
  calculate the Gk for each channel ( in fortran code ). We are just saving
  n-multiplications for n channels of the same ion. 

  I could not find the shift while calculating Gnap in the fortran code.

  250:      DO 88, I = 1, numcomp
  251:       gna_tot(i) = gnaf(i) * (mnaf(i,L)**3) * hnaf(i,L) +
  252:     x     gnap(i) * (mnaf(i,L)**3)

  - this seems to indicate that the equation for gk_nap is:
    gbar_nap * mnaf^3 where gbar_nap is dependent on compartment (gnap(i)) and
    mnaf is parameterized with both compartment no. (i) and level (L).
    
* <2008-12-07 Sun 06:05> Fell into some design problems
  I was tempted into setting the Ek values inside channel creation code. E_NA
  and E_K is constant for naf and kdr and kdr_fs channels. But this was
  actually a bad idea because this actually depends on the cell type and the
  compartment. I realized that for the same type of KA channel, the Ek value
  was different in different cells - although the same channel definition is
  being used all over the place. 

* <2008-12-07 Sun 06:21> Correcting the PyMOOSE code
  I tried the pymoose version now and it seems to require some cleaning
  up. The output is actually same as with two channels only.

* <2008-12-08 Mon 10:50> Voodoo Ik in KDR
  Now after adding more field comparisons and adding NapSS in the models, I
  find that the models are not matching on KDR. The problem field was Ik -
  which should have been initialized to zero but somehow gets a small positive
  value (~10^-12 A) in PyMOOSE. However a newly created HHChannel has Ik = 0.0
  in PyMOOSE.

  Realized that the included GENESIS/MOOSE script had the main code where it
  executed one test - since include in MOOSE causes execution of the whole
  script, the test was actually being executed - and the reset call was
  causing calculation of Ik.

  Further strange behaviour: After fixing the above, it fails on yGate/A
  table. When I dump the tables in channel creation code, the plots are
  identical. But when I plot them in Python after the test ( using pylab ) -
  the behaviour is quite different. The PyMOOSE channel's yGate/A and yGate/B
  are both straight lines.

* <2008-12-09 Tue 07:46> My mistake
  Yesterday's mismath in yGates turned out to be errors in the formula I had
  put in - missing parentheses changed the whole thing.

  Now I have a matching output from PyMOOSE and GENESIS on naf2, kdr_fs, nap
  and ka.

* <2008-12-09 Tue 08:30> Added K2 and KM
  The outputs match after adding K2.  Almost matching after adding km, but I
  can see slight deviation at longer interval. There seems to be an error in
  order magnitude of KM current/conductance.
  
* <2008-12-09 Tue 09:59> AR drastically increases frequency
  Am I doing something wrong? I am worried about the units of alpha, beta. The
  equations for AR are somewhat different, and I am assuming everything in the
  exponent is dimensionless.

* <2008-12-11 Thu 17:10> Trying to understand KC 
  The way I am doing KC setup is not exactly matching neuron model. They
  calculate the Ik depending on the Ca conc at the moment. In MOOSE we can
  only set the Z table ahead. Not sure if applying the same formula ahead of
  time on the interpolation table will give same result.

* <2008-12-11 Thu 20:53> Not sure how to handle Ca2+
  Going through book of GENESIS, I am confused about implementing Ca2+
  dynamics. The book of GENESIS discusses the implementation of Traub 91 model
  where an additional message is created between the compartment and the
  Ca_conc object. But is this required in MOOSE? And how can I incorporate
  this kind of thing in PyMOOSE? MOOSE is not supposed to know about Python in
  any way. May be look up how MOOSE allows addition of new fields / messages
  and provide functions in python to re-implement those things.

  Initially I was just adding I_Ca Ik messages from Ca2+ channels to the
  Ca_conc object.

  Also, in the NEURON model they put a ceiling and a floor (=0) on the Ca
  conc. I don't see how to incorporate this in MOOSE Ca_conc object.

* <2008-12-13 Sat 12:37> Looking at channel behaviour
  After almost completing the single compartment model with GENESIS Ca_concen
  object from my old implementation I see that the frequency has increased
  drastically. Actually there is no structure in the spikes. To understand the
  contribution of each channel I am commenting out most of them and
  incrementally enabling a few channels.

  NaF2 on SS gives a typical spike at the start of simulation due to the
  difference between the cell's resting Vm and Ek of the channel, which slowly
  inactivates. During the current injection it acts just like an RC circuit.

  When I add NaP, the nature of the curve remains the same, only it stays at a
  higher Vm.

  On adding KDR there is nice spiking.

* <2008-12-17 Wed 12:29> Individual channel effects
  Put details in lab notebook. CaT and KAHP I copied from my old
  implementation. Did not verify the equations.
  I need to incorporate CaT, CaL, KC and KAHP in PyMOOSE model.
  Next I should start implementing a whole cell.
* <2008-12-18 Thu 16:01> Corrected the KC and KAHP channels
  Compared my implementation with Traub91 in MOOSE demos. There were a few
  fields I missed to set. One was setting calc_mode for the Z gate tables to
  0. That should not have affected the output. But I also missed the instant
  field (INSTANTZ). After correcting these the frequency has increased
  slightly.  
    
* <2008-12-22 Mon 21:13> Tried a hoc script 
  to simulate a single compartment soma but it is completely different from
  the GENESIS output. There is no spontaneous bursting. The frequency is half
  that of the GENESIS model.
  I am disabling all the channels and incrementally comparing the two outputs.
  Passive compartment - identical output.
  NaF2 - identical output with fastNa_shift_naf2 = -2.5
  NaPFSS - identical output with fastNa_shift_napf_spinstell = -2.5
  With addition of KDR both models fire spontaneously, but the neuron model
  has far higher frequency than genesis.
  - It turned out that I had forgotten to set K+ reversal potential in NEURON
    model. After setting it, the behaviour is identical during current
    injection, but the pre and post injection spikes in neuron are slightly
    delayed (~5 ms). 
  - The passive Em was set -65 in GENESIS and -68 in NEURON model. Correcting
    that fixed the discrepancy in pre-injection spikes. But the post-injection
    pulses are still ~1 ms out of sync.
  - Could not find any error in paramtere translation. Trying kdr alone.
  - KDR alone produces identical output.
  - Just NaF2 and KDR causes the same discrepancy.
  - Adding KA introduces still more discrepancy.
    
* <2008-12-27 Sat 00:01> Is there something with the shifts?
  I suspect that there might be something with the fastNa_shift variable. I
  could get the spike at the start of simulation in GENESIS by modifying the
  shift to 0, though there is one additional spike before start of current
  injection. The outputs are much closer when I set the fastNa_shift in both
  simulators to 0. I need to have another look into the NEURON mod file.
* <2009-03-04 Wed 21:50> Another restart of Traub model
  After a lot of time wasted in reproducing ion channel behaviour Upi
  suggested that I should chuck the idea and move on to the overall network,
  using relatively simplified neurons.
  This was in late January. After coming back from home I was busied with
  travel arrangements for UK and Japan. Nothing more than a successful
  implementation of voltage clamp on squid axon happened during this time.

  As I trid re-running the Traub model, the voltage clamp output is
  horrendous. I am rewriting the circuitry code.
  
  Also Dhanya opined that I cannot learn much by voltage
  clamping. Simulation-wise I think it is too many different clamp voltages to
  be tried for verifying the ion channels.
  But I can definitely verify the resting potential of the channel.
* <2009-03-06 Fri 10:51> Organizing the code
  Trying to reorganizing the code. Global variables and the include model of
  GENESIS is a constant source of trouble. If I just move the global
  assignments around, the code starts breaking (which is expected). Yet to
  figure out the "best practices" for GENESIS script development.

* <2009-04-06 Mon 15:21> Every restart is practically from scratch
  I need some dedicated time for finishing this model: without
  interruption. Avoid distractions, otherwise it is not progressing at all.
* <2009-04-10 Fri 14:59> Restart cortical network
** Globals:
   globals pose a nasty problem as always.
   simdt, plotdt can remain constant.
   simtime cannot. many places (especially dumb tables need to be sized
   according to number of steps) it determines initialization.

   
** Include:
   genesis include system is dumb. if you include a file all code in it gets
   executed. there is not guard from multiple includes other than some
   variable initialization (like #define in C)
* <2009-04-19 Sun 14:10> Checking channels
  Starting with python implementation of NaF and K channels. The testing is a
  pain. Nor behaving properly.  With NaF channle alone I am getting a Gk peak
  at ~18 ms - which is strange.

  I looked in older data src/cortical and saw that a similar 
  spike in Gk even before the current injection has started. May be due to ENa
  and Em and Eleak.

  Separating model set-up, data recording and actual simulation is turning out
  to be a painful process.
  
  These things usually turn out to be monstrous monoliths like a long GENESIS
  session. Not yet able to figure out the best practices for this kind of work.

  The charging  curve for MOOSE was going higher than NEURON with NaF
  channel. So to verify, I removed all channels, and simulated.
  Identical Vm curves for passive compartment.

  Peculiarities of NEURON to remember:
  time unit: ms
  voltage unit: mV
  current unit: nA (?? they put mA/cm^2 for ina in mod files, but in IClamp objects it is in nA)
  
  all resistance/capacitance/conductance are specific, not absolute values. 
  
  spcific membrane capacitance: uF/cm^2
  cytoplasimic resistivity: ohm-cm
  membrane conductance density: S/cm^2
  
* <2009-04-20 Mon 11:47> Reset is not so safe
  I subclassed Compartment to allow nicer ways to insert channel conductances
  and passive properties as specific values (per unit area) as well as
  recording data. I also created a Simulation class to manage the simulation
  at a high level - it keeps track of run-time and lets the user dump all the
  data.
  The passive properties are matching in PyMOOSE and NEURON and so does
  the Vm ( which may seem to be trivial, but I needed to test it to
  ensure that I do not run away too far off due to some silly bug at the
  start of the road. 
  One thing I notice: reset does not really take the simulation state
  back to the beginning. A rerun in the same python process increases
  the membrane potential a lot.
  -- It turns out that it is a little bug in the code - each time I rerun my
  simulation , the addmsg code is reexecuted - and this adds one extra message
  between every src-dest pair. Thus, the injection from pulsegen is doubled on
  second run. - Is this a bug or a feature?

  I cannot record membrane current - Im table is consistently 0 throughout the
  simulation - but the Vm value is showing that the compartment is getting the
  right input.


  - Now getting identical Vm plot from NEURON (test_naf.hoc) and PyMOOSE
    (test.py) models.

  - Now KDR and NaF together working

  - KDR and NAF2 working

  - NaP and KDR not working - when corrected channel density for NaP to
    realistic value, the curves are more similar - but yet nowhere near
    matching.
  - Turned out to be a silly mistake - I was setting gbar for NaP twice in the
    dictionary, the effective one was differing from NEURON.
  - NaP_f and KDR working fine together.

  - NaF_TCR and KDR are not matching. The NEURON mod file is somewhat
    confusing. There are two shift_mnaf parameters: shift_mnaf_init=-3.0mV and
    shift_mnaf_run=-2.5mV. However, the settables procedure has only
    shift_mnaf. And it calculates shift_naf = shift_naf_init +
    shift_naf_run. I suspect NEURON does some funny stuff depending on the
    suffixes _run and _init. The original fortran code has only one shift_mnaf
    which is -3.0mV.

    - Funny: Once I set shift_mnaf to -5.5mV(=shift_mnaf_init+shift_mnaf_run) in PyMOOSE code, it matches
      NEURON simulation. Do not know how they came up with this value for NEURON.
      

  - NaPF_SS, NAPF_TCR both tested against NEURON - working fine.

* <2009-04-21 Tue 14:32> Testing K channels
  KDR working as seen yesterday.
  KDR_FS working with NaPF_SS
  KA is not working with NaPF_SS and KDR_FS

* <2009-04-22 Wed 00:27> KA channel fixed
  It turned out that NEURON version is initializing the m, h state variables
  to non-standard stuff (in theory they should be functions of voltage, and
  calculated on the fly). I had to modify HHChannel code to allow for initial
  values for these state variables.

  Now I am getting mismatch with KA_IB. This is just KA with tau_h multiplied
  by 2.6 (god knows why, obviously to fit the graphs as best as possible).

  Oops! looks like the initX/Y/Z is not working - the date has changed and I
  have been trying to match KA(yesterday's output) with KA_IB. 
  After I realized the blunder, and compared the correct plots, the initial
  part has a little discrepancy. When I set X for KA_IB after the reset, it
  works, but when I set initX, it does not.

  Well - now I have fixed PyMOOSE to make it work. KA_IB is matching.
* <2009-04-22 Wed 10:29> Ca channels
  CaT worked after I corrected unit conversion in the formulae for alpha and
  beta. CaL was having similar problem, and after fixing unit conversion it is
  very close.

  Fiddled with beta, changes as drastic as multiplying by 1000 does not make
  any difference in plot. The little difference with NEURON plot may be at
  alpha.
* <2009-04-23 Thu 08:45> Fixed CaConc
  CaConc was not matching. After fixing tau, it works after scaled 10^3
  times. Don't know why, because NEURON declares mM as unit - which is
  equivalent to the SI unit used by MOOSE. 

* <2009-04-23 Thu 15:29> Found bug with Ca pool
  Realized that the cat current does not participate as source in ca
  pool. It was working because the influx due to CaL was overriding the
  discrepancy due to CaT.  Lost all commits beyond the working Ca pool version
  in a confusion with git. 'git checkout version' somehow reverted the commits
  themselves, or may be something stupid I did with egit in emacs. git does
  not seem to be as cool as svn.
* <2009-04-25 Sat 00:43> Is there a problem with Ca2+?
  I am struggling to get correct results with Ca2+ and dependent K channels
  (KAHP). 
  1. The NEURON [Ca2+] is 1000 times that of MOOSE.
  2. The rising part of the [Ca2+] is identical. 
  3. The falling part of the [Ca2+] goes off like the time when I was putting
     wrong tau (1/tau instead of tau).
  4. (2) and (3) above makes me think that there is something wrong with decay
     constant. In rising phase, B dominates, and in the falling phase, tau
     dominates. But what is wrong with tau?
  5. The tau in GENESIS model generated by NeuroConstruct is completely
     different.
  6. My suspicion is supported by the fact that when I double tau, [Ca2+] is
     almost identical during the falling phase.
  7. But there is no happy ending: the final phase is again a rising phase (
     when current injection is stopped and the compartment starts to
     repolarize), this is still deviating.
  8. When I plot kahp_m from moose against that from NEURON, the plot has two
     straight lines: one with a slope ~0.5 from (0,0) to (0.018, 0.009) and
     then with slope 1.0 (which is the wanted slope) for the rest.

* <2009-04-26 Sun 17:03> KAHP still the trouble
  Now I am trying without any current injection. Right at the beginning MOOSE
  [Ca2+] goes up very steeply, while NEURON has a low slope at the beginning. 
* <2009-04-26 Sun 22:45> KAHP solved - but CaL not exact
  Found the bug with KAHP - the tables were not fine enough. The conditional
  evaluation was getting lost in the process. 
  But still there is a small discrepancy in [Ca2+]. May be something's wrong
  with CaL. I tried with CaL alone without any input current - and [Ca2+] is
  deviating right at the start. Later on it stays ~parallel to NEURON.

  Checked X_A and X_B tables with NeuroConstruct's version - identical
  values.

  Checked with the commit where I thought the Ca channels were working - no -
  the out put is very close - I did not recognize the difference as the plot
  symbols were bigger than the difference. The difference is there during the
  first few milliseconds.

  Compared [Ca2+] with that from NeuroConstruct-generated  code. That is still


  further off from NEURON output.

  Finally FOUND the BUG!
  I had originally set cal.xGate.initX = 0.0 - but the initX field was removed
  after Upi suggested a better way of mainitaining initialization info. The
  old initX = 0 code was not corrected. Once I fixed it, the result is
  perfect!

* <2009-04-27 Mon 02:27> KC - the last hurdle
  Just implemented KC, as with erroneous KAHP, here also the rising phase is
  more or less identical but the falling phase [Ca2+] goes off, Vm is quite
  far away.
  Too sleepy to debug.
* <2009-04-27 Mon 11:06> Final victory (over ion channels in a single compartment)
  Finally KC also worked. I was not putting the correct scale factor on
  correct term.
* <2009-04-27 Mon 15:22> Yes, indeed!
  NO! It's not yet over
  AR remains to be matched.
  <2009-04-27 Mon 15:30> - Got it going - had forgotten to scale tau_m.
  Tested CaT_A OK.

* <2009-04-27 Mon 21:37> All together it is not working :(
  Inserted all channels corresponding to compartment 2 of spiny stellate cell from
  NEURON model, not matching. There is a spike at the beginning - which is
  identical, but the two differ from the end of that spike.

* <2009-04-27 Mon 21:43> Final victory (for the time being)
  I had just missed out the Ca pool. After inserting it, it's quite good
  match. But the first spike is now deviating more than before.

  Now I should write down some code to test out each channel in the minimal
  setting. Till now each channel is a different GIT commit.
* <2009-04-28 Tue 20:03> Not yet 
  A bug seems to have creeped into the test.py code. [Ca2+], when tested
  with CaL alone, has suddenly changed scal (10 times larger). Will revert to
  an older version and redo.
* <2009-04-30 Thu 03:02> Spiny Stellate cell
  Spent half of the day writing a pretty-printing utility for MOOSE tree. 
  
  Then concentrated on SPiny stellate cell model. Got the geometry correct (I
  hope). Added all channels ( emacs tricks came very handy to copy these from
  hoc script). Did the simulation for 50 ms, but the Vm plot does not look
  convincing. 
* <2009-05-01 Fri 00:26> Far off 
  Just tried a single spiny stellate cell. Soma is stimulated with 0.3 nA
  current and Vm is recorded at fourth axonal compartment from soma, and the
  frequency is way too high.

  The reasons could be:
  1. I messed up the injection current. - Just checked - that does not seem to
     be the case,
  2. There is something wrong with the connection
     - From the tree of the cellular connection, it seems the parent child
       relation is fine.

     - There may be a mistake in connecting raxial. I am not sure if the
       message is symmetric or not. I assumed it should be (simple ohmic
       resistance).
  Need a better look into onecell.hoc - which creates and runs a single cell.
* <2009-05-01 Fri 11:20> One error found
  I realized that axonal structure branches into two but I had made it
  linear. After fixing that, the spiking frequency is much lower. 

  Still it is quite different from NEURON.

  The initial membrane potentials were different (-65 and -60 mV).
* <2009-05-02 Sat 16:59> Corrected axon
  Apparently I was inserting channels even in axonal compartments. Noticed
  just now and corrected to insert channels.

  I forgot to include axons in level 0. So they were not getting any
  channels. Now it is fixed and the spike shapes look a little better.
  
* <2009-05-03 Sun 16:05> Trying Spiny stellate
  KDR_FS - identical
  NaF2 - the spike is delayed - could be something with fastNaf_shift

  NaPF_SS - does not seem to have any effect

  THE PERFORMANCE BOTTLENECK

  The setup takes terribly long time.
  The reason for it is that I am calculating the m, h tables for each
  instantiation of each channel - this causes extreme slowdown. Ideally the
  tables should be class variables. But the shoft parameter comes in the way. 

  A better workaround will be using copy in MOOSE. But I don't know how to do
  that. I avoided library, prototype in PyMOOSE. But looks like I need to put
  them in.

  - NO THE BOTTLENECK is NOT NUMPY ARRAY CREATION - when I move those to class
    variables, there is only about 3% reduction in time to create all the
    channels. 
    - Likely to be in the looping through all tables and assigning
      values.
* <2009-05-03 Sun 23:31> KC is making problem
  Looking through the code again - comparing channels one by one.
  KC turns out to be the culprit.
* <2009-05-04 Mon 23:11> Todays commits are gone!

  Not that it was a lot of code - but git-emacs did something silly and that
  screwed up the whole system. I am losing faith in Linus. git is
  annoying. When branches are cheap, one ends up with many branches and then
  forget what is what.
* <2009-05-05 Tue 14:42> Bad design
  I did not think about the duplication of the gate tables in all the
  channels. Ideally the channels of the same class should share gates. But
  although PyMOOSE has provision for copy constructor that just does that, I
  did not design my channel subclasses for that. As I tried to derive a way
  to create a copy for all but the first instance, I realized that I shall
  need to change the signature of all the classes for that (in my python
  code). Now the way is to explicitly create channel objects in the library
  and then copy them in compartment code. 
  Also, the channels varying only by shift will need to be created separately.


  I had to set the Ek values based on prefix of the channel names - something
  I had tried to avoid by creating a whole class hierarchy in python. I feel
  we are doomed to string based decisions in this kind of system. The kind of
  friction I am going through in Python is perhaps due to a fundamental
  difference in the way of thinking. Things might have been smoother if I just
  wrote genesis script using python syntax.
* <2009-05-06 Wed 17:25> Spiny stellate - more fun
  In order to track the strange behaviour of ss cells, I tried removing the
  dendritic arbour level by level. 
  soma with axon - three spikes at the beginning
  soma, axon, first level of dendritic compartments - spike count reduced to 2
  (?)
  soma, axon, second level of dendritic comp - 1 spike
  soma axon, third level dendritic comps  - no spike.

  It turns out that the Gk of NaF2 goes 4 orders of magnitude down when
  shift=-2.5 mV.

  
* <2009-05-08 Fri 21:33> Added a brute force version 
  - mostly copy - paste - regex_replace in emacs from spinstell_template.hoc -
    to minimize typos. No help.

* <2009-05-13 Wed 11:28> Switching to TCR
  As the spiny stellate cell is not working, I am going to move to TCR which
  is more symmetric. Also neuroConstruct has the cell morphology working.

  This time I should move incrementally - just adding one compartent at a time.
* <2009-05-15 Fri 15:59> Back to spiny stellate
  Trying to do it incrementally. Now testing just soma, axon and the dendritic
  compartments adjacent to soma.
* <2009-05-18 Mon 02:19> Soma Vm does not match
  Tested the non-brute spinstell with just soma with neuron - not a perfect
  match any more. Will start over.
* <2009-05-18 Mon 03:59> KDR_FS mismatch 
  I resorted to the painful technique of removing all channels and then adding
  them back one by one  - NaF2 and NaPF_SS give identical results. KDR_FS
  causes problem.

  When I put KDR alone, they behave more or less same.
* <2009-05-21 Thu 00:07> Compartmentalization problem?
  Just out of frustration I added one extra compartment at the end of the
  axon, and voila, the results are almost identical - looks like there is a
  compartmentalization problem. - <2009-05-21 Thu 02:18> I tried again now
  after putting and removing the dendritic tree - that extra spike is missing
  now. Mat be I am too sleepy.

  With that part working I switched to the full tree - but strangely the Vm 
  plot remains same - something is not getting updated.

  Found it: the length in the levelno-length map was in microns, but I was not
  converting it to SI. 

  Now the outputs are quite far apart. When I try only the dendritic
  compartments adjacent to the soma, the outputs are pretty close, and now the
  extra axonal compartment is not making much difference.
* <2009-05-23 Sat 15:25> Upi's suggestion
  Upi suggested I should change the axial resistance of the extra branch to
  very high (so that it becomes practically disconnected) and see if the
  solver is handling it correctly.
* <2009-05-25 Mon 23:13> Checked connectivity
  I printed out the connectivity in python and neuron models - and they are
  identical (brutespinstell.py and mycell.hoc). So the error is happening
  somewhere else.
* <2009-05-26 Tue 15:53> Compared brutespinstell
  I did a comparison of all single compartments in neuron and python - the
  compartments are isolated and injection and recording happen on the same
  compartment. The plots are identical.
* <2009-05-26 Tue 23:58> Axial-Raxial problem
  I just switched the direction of connection [soma.raxial->axon.axial to
  soma.axial->axon.raxial] and that did the trick.
  
  Silly me!

  But but but ... after this correction, brutespinstell encounters the same
  problem - one extra spike before current injection as I add all the axonal
  compartments.

  MOOSE is badly affected by dt - 1e-4 gives quite different results from
  1e-6. 1e-5 is reasonable. 1e-4 is problematic because each ms of simulation
  is done with only 10 time points, but comparatively neuron simulation is
  much faster. Adaptive time steps??

  Problem with spontaneous second spike: the branching does not really
  matter - even if I add the extra axonal comp at the end or as a branch the
  output matches. But if I increase the Ra for compartments upstream, the
  firing does not happen.
* <2009-06-01 Mon 22:22> Shameful mistake
  I realized that I was using diameter as radious for calculating cross
  section of compartments - after correcting for that the outputs are decent. 

  But there is some problem with KDR_FS and NaF2 - if I try these two channels
  only on the soma, the outputs don't match. Given that I was getting perfect
  match in singlecompartment test, this should not happen.

  The problem is KDR_FS alone is giving identical results in the
  compartment. So is NaF2 alone.
* <2009-06-02 Tue 14:35> Single compartment match
  The problem factors were dt and secondorder statements in NEURON.
  once I added:
  secondorder=2
  dt=1e-3
  
  single compartment soma outputs were matching nicely.
  
  But as I restored the connectivity to all the compartments, the outputs are
  differing as before. ALso, when I removed the injection current the outputs
  seem to be highly different. Need to check once I come back from animal house.

* <2009-06-02 Tue 19:46> Dendritic compartments cause problem
  As I add a dendritic compartment the outputs start differing. Just soma and
  one denritic compartment also differs.
  When I switch the direction of axial-raxial connection - the output of MOOSE
  goes haywire.
  But single compartment test works on the dendritic compartment.
  Things to check: 
   spine area multiplication is correct.    
   Ra is correct
   Dimensions are correct

 I tested the passive soma - d1 pair - and they are differing : something is
 wrong with Raxial

 No! there is a problem with passive properties. I switched the 
  
* <2009-06-02 Tue 23:32> Problem in passive properties
  brutespinstell.py has some problem with passive properties: because when I
  create a separate two compartment passive model with soma and first
  dendritic compartment settings, it matches with the neuron Vm.

  Just checked the passive properties of brutespinstell compartments (soma and
  comp[2]) and test_twocomp - identical. 

* <2009-06-05 Fri 10:47> HSolve not present
  I realized by showmsg() that the brutespinstell is not getting a
  solver. This is strange - the class is derived from moose.Cell and all the
  compartments are under this object.
* <2009-06-06 Sat 12:28> HSolve present but hub not connected
  pymoose.showmsg(moose.Neutral('/model/cell/solve/hub'))
Info: PyMooseBase::PyMooseBase(Neutral, /model/cell/solve/hub) - Returning already existing object.
INCOMING:
[/model/cell/solve/hub].child <- [/model/cell/solve].childSrc
[/model/cell/solve/hub].integ-hub <- [/model/cell/solve/integ].integ-hub
[/model/cell/solve/hub].child <- [/model/cell/solve].childSrc
OUTGOING:
[/model/cell/solve/hub].compartmentSolve -> [/model/cell/comp_59].process
>>> 

So solver is getting created but only compartment 59 is connected to the
hub. Why?

- Niraj told me that the solver starts with the last created compartment and
  traces the whole cell by tracing connectivity between compartments. Thus a
  forest of compartments is not handled correctly by the solver.

  So I have to remove all other compartments and do the simulation. So I guess
  my full cell model is the best I can get with the solver ( because all the
  compartments are connected).
* <2009-06-09 Tue 02:37> Three compartments 
  Soma, comp[2], comp[3] where comp[3] does not have any ion channels works
  fine. But when I add ion channels, it deviates slightly. I am going to
  accept it and move on with the other cells.
* <2009-06-09 Tue 23:30> Regular expression 
  Some useful regular expressions for this particular case:

  To replace all occurrences like:

  comp[ 1] { level[ 1].append() L=  20. diam = 2*  7.5 }

  by the corresponding python statements:

	level[1].append(comp[1])
	comp[1].length = 20.
	comp[1].diameter = 2 * 7.5

  use following regexp search:

  comp\[ *\([0-9]+\)\] *{ level\[ *\([0-9]+\)].append() L= *\([0-9]*.[0-9]*\) *diam = 2\* *\([0-9]*.[0-9]*\) *}

  and replace by:

  level[\2].add(comp[\1])
  comp[\1].length = \3
  comp[\1].diameter = \4

  Another alternative that reduces typing in the replacement string is:


\(comp\[ *[0-9]+\]\) *{ *\(level\[ *[0-9]+\]\)\.append() *L *= *\([0-9]*.[0-9]*\) *diam *= *\(2\* *[0-9]*.[0-9]*\) *}
  replaced by:

  \2.add(\1)
  \1.length = \3
  \1.diameter = \4

  Then select the whole region, replace ]. with ]. (to make the
  length/diameter/add/ as 3rd field) and select area again use C-u 3 M-x
  sort-fields. It will separate out the level.add(), comp.length = xyz and
  comp.diameter = uvw into three separate blocks. Then kill rectangle and yank
  rectangle will do the trick.
* <2009-06-29 Mon 16:12> Restarting 
  - there was a break of a couple of weeks since TCM (15 June
    2009). Restarting this work.
* <2009-07-16 Thu 23:57> Another restart
  Drifted away by MOOSE release and optogenetics course - another trial .. now
  I seriously doubt the fate of this project.
* <2009-07-23 Thu 23:46> TCR - automate comparison
  Now I finally managed to put together some code for automatically dumping
  the cell parameters and comparing them. Code for dumping teh parameters in
  neuron is in hoc/utility.hoc and that for TCR cell in pymoose is in tcr.py
  (dump_cell). The comparison program is compare.py. Parameterwise I am
  getting an exact match to 1e-3 error, but plots are very diffrent. Could be
  due to stimulation difference. Also, I should check the same code against
  spinystellate to verify that the code indeed works.
* <2009-07-24 Fri 14:29> TCR - some match finally
  My comparison code yesterday had epsilon=1e3 instead of 1e-3 - hence
  everything was matching. After correcting that today, I took spinystellate
  as the model and scaled all parameters so that spinystellate cells
  match. Then comparison code showed that I was making a mistake of one
  decimal place for Ca2+ B. After correcting this, the two are pretty
  close. But funny thing is that the neuron gui shows several spikes whereas
  my version shows only two spikes.
* <2009-07-27 Mon 00:30> NeuroConstruct generated code
  While trying to load NeuroConstruct genenrated GENESIS code for TCR in
  MOOSE, there were errors on tab2Dchannel - it turned out to be due to some
  constant not defined in MOOSE:VOLT_C1_INDEX - I am not sure why this is
  being used. Another thing I noted was that the kahp_slower channel is only
  [Ca2+] dependent, not voltage dependent - so there is no real need for
  tab2Dchannel.
* <2009-08-04 Tue 04:00> NeuroConstruct generated code - can mostly read now
  I fixed the Interpol2D class and str2val for getting indices. This solved
  the problem of loading a HHChannel2D using GENESIS script. And added the
  Leakage channel type.

  Also added more code to dump neuron info in NEURON - so should be easier
  now - but it is getting uglier at the same time - equivalent to doing a
  readcell.

* <2009-08-04 Tue 22:20> Readcell
  Finally I switch to printing the NEURON parameters in readcell format and
  then using readcell to read it in.
* <2009-08-06 Thu 15:14> Readcell - todo
  Some parameters are not accounted for in readcell format: tau for
  CaPool. Erev for channels - which varies from cell type to cell type. 
* <2009-08-12 Wed 00:24> Further changes using readcell
  Refined the TraubCell class to set the channel reversal potentials.
  Also added something to set Rm and Ra, but then realized that they can be
  put in .p file.
  Switched call to readcell_scrambled in TraubCell to PyMooseContext.readCell
  as readcell scrambled cannot preserve the position of compartment specific
  parameters. So using readcell_scrambled to sort out the sequence of
  compartments. Then inserting the compartment parameter statements at correct
  place manually.
* <2009-08-12 Wed 13:50> A better way to debug Python module _moose.so
  http://book.opensourceproject.org.cn/lamp/python/pythoncook2/opensource/0596007973/pythoncook2-chp-17-sect-9.html
  Break on _PyImport_LoadDynamicModule

  This will stop at every module being loaded, after which we can put a
  breakpoint on any symbol in _moose.so.
* <2009-08-28 Fri 12:40> Ca concentration issues
  The B parameter for Ca pool in .p file I generate is half that in the
  neuroconstruct generated stuff. 
  I found that the reason is that NeuroConstruct makes compartments half the
  size of those in the model. As B is calculated as phi/A, my version gives a
  different result.

  Still the results are far off from NEURON.
* <2009-08-31 Mon 21:49> Far higher frequency 
  I am getting far higher frequency than NEURON model and my model spikes
  spontaneously whereas the NEURON model spikes only at current injection.
* <2009-09-07 Mon 18:49> Ca was the culprit
  Not yet solved - but as I started recording [Ca2+] it was all 0. Then I
  figured that the readcell was not able to tell Ca dependent channels from
  others. So I put code to explicitly connect the CaPool to the CaL channel
  for Ca2+ source and to KCa channels as source of concentration - and this
  changed the firing behaviour drastically. Now it fires 3 times in first 4
  milliseconds (too high) and stops after that - not sure why.
* <2009-09-08 Tue 11:00> Passive properties - OK
  Only difference was Em - which was set to -65 mV in my code and -70 in
  neuron - after changing passive cell behaves OK.
** Blocked Ca channels and Ca dependent channels - differ
** Only Na channels - the high happens early in moose - likely culprit
* <2009-09-09 Wed 18:08> Fixed SupPyrRS  - almost
  Now within 10 ms window behaviour is identical - earlier problem was because
  NaF shift was missing. Change utility.hoc to write scaled value of B for [Ca2+].
* <2009-09-11 Fri 01:31> Checking for 100ms run time
  There was significant discrepenacy in time for the second spike when I ran the
  simulation - now I am trying the channels one by one again.
** Na channels - passed
** Na + KDR - hyperpolarization of neuron model is more than mus - Ek of K channels?
   I had forgotten to uncomment ek for neuron model.
   After correction - first spike matches exactly - but then they start going
   out of sync...
** KDR Alone - after 30 ms mus and nrn plots start diverging
** KA Alone - good match - now I have serious doubt about KDR
** KDR, KC and KAHP blocked - slight variation
** KC enabled, KDR and KAHP blocked - significant variation
** KAHP enabled, KDR and KC blocked - significant variation after the first spike..
* <2009-09-11 Fri 14:18> Now KDR works!
  As I retried to compare KDR only models - voila - the plots are
  identical. Looks like I was missing some compartments when
  enabling/disabling channels. Effect of wee-hour programming!!
** NaF, NaP and KDR work together
** KC - causes serious discrepancy from second spike
** checked [Ca2+] :: moose * 1e3 = neuron
   It is getting built up according to the formula:
   [Ca2+]' = B * I - [Ca2+]/tau   
   Now I is in mA in neuron and A in moose - so B * I will be scaled up by
   1000. Also tau is ms in neuron and s in moose - so this too, ... no the
   dimensions are messed up! So let us assume everything else is fine except
   the scale factor for [Ca2+] - as shown bu the plots - so how to rescale KC
   Zgate tables to behave properly?

   
* <2009-09-12 Sat 22:13> KC and KAHP only hardles
  Now all other channels are behaving properly - only KC and KAHP - the Ca
  dependent channels have to be fixed. Now I will try brute force approach -
  plot Gk (or Ik) / (v - ek) against [Ca2+] and reverse calculate the
  appropriate function for MOOSE.
* <2009-09-14 Mon 09:43> KC ....
  The neuron formula for ik_kc is:
  if 0.004 * cai < 1
	ik_kc = gbar * m * 0.004 * cai * (v - ek)
  else
	ik_kc = gbar * m * (v - ek)


  So, since moose cai is 10^-3 times that in neuron, the formula should be
  
  if 4 * cai < 1:
	ik_kc = gbar * m * 4 * cai
  else
	ik_kc = gbar * m * (v - ek)

  But this does not help.
  I tried plotting g_kc for neuron against moose - initial part is
  non-linear. Now removed the Ca dependency from both versions and checking if
  m parameter is ok.
* <2009-09-16 Wed 00:41> Some crazy behaviour explained?
  Fortunately I had backed up 12 Sept. code in magaj home. After copying the
  older code I am getting good match. It seems that the gbar_xyz = 0.0 was not
  equivalent to commenting out 'insert xyz' statement.
* <2009-09-16 Wed 10:22> Now OK it seems 
  The current version is kind of working ... for the enabled
  channels. committing to git for back up.
  Now the KC channel is matching up nicely. Cannot believe that computer
  simulations could be so temperamental - varying from day to day with no
  apparent reason. It won't be surprising if I become superstitious like
  biologists. Hopefully these variations only reflect my sleep deprivation
  levels.

  Even KAHP and CaL together are matching after the scaling.
  Now I am going to put back all the channels. Good luck!!

  kc, kahp, cal, cat - OK

  kc, kahp, cal, cat, naf - NO

  naf - OK

  cal, cat, naf - OK

  cal, cat, naf, nap - OK

  
  cal, cat, naf, nap, kc - NO

  - looks like naf and kc together messes up

    naf, cal, cat - slight difference in [Ca2+] - which worries me.
* <2009-09-17 Thu 00:22> CaConc is the trouble
  I spent the most part of this evening trying to find the source of the
  problem. And with KC and CaConc enabled and with a high depolarizing current
  injection it became obvious that the [Ca2+] is the culprit. The neuron model
  sets floor and ceiling values on [Ca2+] and the floor(0.0) is reached - in
  MOOSE it goes negative.

** MOOSE code change
   I added floor and ceiling sttings in MOOSE and that made the plots much more
   similar. Yet, with KM present the MOOSE [Ca2+] goes up from 0 earlier than
   the NEURON model.

   Without KC the discrepancy is much smaller and comes very slowly.

** Finally - this small discrepancy turned out to be due to KC - I was putting 
   xGate.A = alpha
   xGate.B = alpha + beta
   and calcMode = 1 for each as well as making them instantaneous. After
   putting beta in B and doing a tweakAlpha and unsetting the instant property
   of xGate, it is working with KC and CaL.


** KAHP - 
   Now I added KAHP and there was little difference. Then to verify that KAHP
   was really working I disabled KC. It showed a small difference at the
   peak of Vm as well as a slow deviation of [Ca2+]. I don't know when it is
   going to bite.

** All channels
   for 200 ms the Vm plots match nicely. But the [Ca2+] plots deviate from the
   Ca2+ peak onwards - much like the earlier issue with KC.
   
** KAHP blocked
   Still the deviation in [Ca2+] is present.

* <2009-09-17 Thu 09:52> More shock
  Now that [Ca2+] is matching for high injection current, when I put KC and
  CaL together it does not work anymore. There must be something in the
  scripts themselves - because even after reverting back to older version of
  pymoose library, it remains the same.
** KAHP solved 
   The KAHP issue came because I had made the instantaneous calculation
   on. AFter correcting that I got exact match for KAHP.
   -- Now the protocol is:
   50 ms - start 0.3nA injection
   100 ms - stop injection
   150 ms - start 0.3mA injection
   160 ms - stop injection
   200 ms - end simulation
** KAHP + KC - working
   but the mus peak at 0.3mA injection is slightly (mus: 1370mV, nrn: 1385mV)
   for lower.
** KAHP + KC + CaL + NaF 
   glitches - towards 150 ms
* <2009-09-17 Thu 16:28> All channels
  Almost good match with all channels enabled : only glitch is the last spike
  in moose repoloalizes to a lower Vm than nrn.

  
** Disable KDR - more discrepancy 
   - so KDR was actually balancing the discrepancy.
** Disabled KDR, CaL, CaT, KC, KAHP
   - I have checked the last four to some extent and expect the culprit to be
     some other channel.
   - not much good - the moose plot is very slightly delayed ~0.22 ms
** Naf & ka enabled
   Much less difference: 0.05 ms
** NaF, KC, CaL
   Bad .. after the first bunch of spikes there is silence ~20ms. Then another
   bunch of spikes .. the discrepancy going higher and higher.  Last peaks are
   almost 2 ms apart.
** NaF, KC - CaL blocked
   Not much difference, yet moose has a very slight lag.
** NaF, CaL
   Back to the same stage as exp. 6 yesterday. [Ca2+] does not match. Now I am
   going to check the analytical expressions for these two and compare
   successive [Ca2+] values based on Vm. Using difference formulae I should be
   able to tease out the problem source.
* <2009-09-21 Mon 02:35> Refined utility.hoc
  Now prints compartments in root->leaf sorted order and with EK, RM, CM and
  RA as compartment parameters in .p file. Still have to set channel reversal
  potentials in python code.
* <2009-09-22 Tue 23:46> Retracted modification in Ca2+
  As Upi suggested - in order to avoid performance issue in hsolve I made
  Niraj retract the changes I made in hsolve (floor and ceiling for [Ca2+]). And I checked that the behaviour
  did not change when all channels are enabled. 

  But there was some serious bug in hsolve in that it did not use the xmin and
  xmax values set by the user on an interpolation table but used default
  constant values. We found this from a problem Padraig was facing when trying
  to use physiological units. This might well have caused me some headache -
  as I was using.
* <2009-09-22 Tue 23:56> Looks like hsolve bug was the culprit
  Now after Niraj did the bugfix, I am getting exact match with all channels
  enabled in SupPyrFRB.
* <2009-09-24 Thu 17:55> SupLTS - CaT_A not matching
  NaF2 missed the shift. Fixed that. Now CaT_A is not matching. Checked the
  m_inf, m_tau, h_inf and h_tau calculations - allright.
* <2009-09-25 Fri 21:25> CaT_A : mus = genesis
  Just tested the same test script with MOOSE and GENESIS - identical.
  Genesis and Neuron give almost identical result. PyMoose output is less.

** Finally found the bug when comparing the gate tables
   I happened to use the tauh, taum, minf and hinf from CaT in CaT_A: this
   happenned because I had copy pasted the CaT class and edited it to make
   CaT_A - forgetting to change the CaT.minf to CaT_A.minf.
   
* <2009-10-06 Tue 16:49> Superficial Layer 2/3 Basket Cells
* <2009-10-07 Wed 14:13> Fixed Padraig's code
  Padraig's code for NaP channel of Traub model had a silly mistake - vmin and
  vmax were swapped - fixed.
  RandomSpike was not working for him. Turned out the it did not have default
  scheduling: However useclock solves it, I updated moose RandomSpike class to
  enable default scheduling. Not yet sure which clock should be scheduled to.
  Printing channels twice: he was trying to print hh_channel and tabchannel
  separately - but they are the same class in MOOSE - so I advised him to wrap
  one with a version check for moose.
* <2009-10-07 Wed 14:17> SpinyStellate - new version
  Not working - initially I had not set cartesian, asymmetric and relative
  options in the .p file. After fixing that the HHChannel Ek were not set
  properly - I was setting Ek without casting the object to an HHChannel. Now
  the cell comparison gives exact match.
  Still it is nowhere close to the neuron output.

** Testing individual channels
   - [X] passive
   - [X] NaF2
   - [X] NaPF + NaF2
   - [ ] NaPF + NaF2 + KDR_FS  - NO
	 after 20 ms the spike times drift off.
   - [X] KDR_FS
   - [ ] KDR_FS + NaF2 
	 After 20 ms spike times drift off - may be initial value of m and h
         gates.
	 I fixed the initial values for m gate in the channel codes - still
         same problem.
   - [X] NaF2 + NaPF_SS + KA + K2 + AR 
	 NO
	 not exactly matching
	 <2009-10-07 Wed 16:43> after I set initial value of m table to 0.0 it matches.
   - [X] NaF2 + NaPF_SS + KA + K2 
   - [X] NaF2 + NaPF_SS + KA + K2 + AR + KM
   - [X] NaF2 + NaPF_SS + KA + K2 + AR + KM + CaT_A
   - [X] NaF2 + NaPF_SS + KA + K2 + AR + KM + CaT_A + KDR_FS
   - [ ] NaF2 + NaPF_SS + KA + K2 + AR + KM + CaT_A + KDR_FS + CaL
	 NO
   - [X] CaL
   - [X] CaL + NaF2
   - [ ] CaL + NaF2 + KDR_FS
	 difference spike timing by < 1 ms
   - [ ] CaL + NaF2 + KDR_FS + KA + K2
	 Same for 30 ms, goes out of sync after that.
   - [ ]  NaF2 + KDR_FS + KA + K2 + KM + AR
	 Same for ~40 ms, goes out of sync after that.
   - [ ] WIth all channels in and setting m0 = 0 for AR, it almost works (the
     spike time goes out of sync at ~100ms. But shape is very similar.

* <2009-10-08 Thu 11:19> Complete layer 4 -> layer 2/3
  Now I have the following set of cells functioning:
  - Spiny Stellate (L 4)
  - LTS (L 2/3)
  - Pyramidal FRB (L 2/3)
  - Pyramidal RS (L 2/3)
  
  TODO:
  - Basket cells (L 2/3)
  - Chandelier/axo-axonic cells (L 2/3)
  - Some cell types are lacking in Traub model 
    1. L 4 Interneurons
    2. L 4 star pyramidal
       Not sure if 'superficial' basket cells are in L4 or L2/3
* <2009-10-08 Thu 19:01> Basket cell - done
  I finished the basket cell and it matched in the first go!
* <2009-10-16 Fri 10:06> Release it!
  I'll add this as a demo to the MOOSE subversion repo. For that I want to do
  all the cells - which is a no-brainer now.
  The list of cells:
- [X] deepaxax_template.hoc
- [X] nontuftRS_template.hoc
- [X] supaxax_template.hoc
- [X] suppyrFRB_template.hoc
- [X] tuftIB_template.hoc
      -- this is not matching
      -- The CaCon tau was set specific for each compartment in level2 - after
      fixing it matches.
      -- But No spike when current injection is applied at 50 ms for 50
      ms. Spikes come when current is injected right at the start of the
      simulation and stays on for the duration of the current injection.
- [X] deepbask_template.hoc - the last spike is slightly off
- [X] nRT_template.hoc - not matching
      - only passive - matching
      - only noticed that NaF2 did not have -2.5mV shift in this case -
        created another specialized channel - much closer
      - only NaF2 - matching
      - only KDR - matching
      - NaF2 + KDR - matching
      - NaPF - matching
      - NaF2 + KDR + NaPF + K2 - matching
      - NaF2 + KDR + NaPF + K2 + KM - goes out of sync after some time
      - KM alone - matching at 0.3 nA, matching at 10 nA
      - KM + NaF2 - match
      - KM + NaF2 + KA - match
      - K2 + KM + NaF2 + KA - match
      - K2 + KM + NaF2 + KA - match
      - K2 + KM + NaF2 + KA + NaPF - match
      - K2 + KM + NaF2 + KA + NaPF + CaT_A - match
      - K2 + KM + NaF2 + KA + NaPF + CaT_A + - slight mis-match
      - AR alone - not matching - m0_ar is set to 0 for this cell - in others
        it is -2.5 mV
	- after correcting this all spikes except the last one are matching.
      - ['NaPF', 'NaF2_nRT', 'KM', 'KA', 'K2', 'CaL', 'CaT_A', 'AR',
        'KDR_FS'] - match
      - ['NaPF', 'NaF2_nRT', 'KM', 'KA', 'K2', 'CaL', 'CaT_A', 'AR',,
        'KDR_FS', 'KC' ] - match

      - Added KAHP_SLOWER to above - last spike out of sync - looks fishy -
        many other cells have the same problem : KAHP_SLOWER is culprit?
	
      - Set calcMode = 1 for KAHP_SLOWER and it works!!
	
- [X] supbask_template.hoc
- [X] suppyrRS_template.hoc
- [X] tuftRS_template.hoc
- [ ] deepLTS_template.hoc
- [X] spinstell_template.hoc
- [X] supLTS_template.hoc
- [X] TCR_template.hoc
* <2009-10-22 Thu 14:36> Visualization
  I have been googling around and reading mailing lists / documentations in
  search for a good 3D visualization library in Python. What Karan has been
  doing is great: but I am not sure how it will integrate with Python. Because
  he has a stand-alone app for visualization, the number of processes to be
  handled in Python increase. Also, I suspect that this standalone application
  will need some wrapper code to integrate with PyQt. 

  On the other hand, if I can make a 3D visualization widget using existing
  python-opengl libraries, it can utilize Karan's class that writes out data
  from MOOSE for the visualization application and seemlessly integrate with
  PyQt gui.

  Regarding this I am considering the following:

  1. VPython - small (2.4 MB), object oriented, high-level (has basic solids
     like cylinder built-in - so I just need to put the compartment x,y,z and
     diameter into it), interactive, easy to learn for novice programmars.
     - Though it seems sufficient for MOOSE, I am not sure how far it can go
       if we need more sophisticated 3D rendering in future.

  2. MayaVi2 / VTK - big (~10 MB), targeted at scientific data
     visualization,comes with built-in gui. renders 3D surfaces. 
     - Does not look easy. Seems to be oriented more towards 3D data rather
       than standard shapes. Release version requires wx threads. PyQt support
       incomplete and not well documented, available as source code only.
     - Some lists said it is easier to use VTK directly and that resolves the
       blockage with PyQt.

  4. Panda3D - huge (~60 MB). Targeted at industry quality 3D animation and
     gaming. Portable between mac/linux/windows. Has lots of extra
     functinoality (like utilities for online multiplayer gaming). Well
     supported by Disney and CMU.
     
* <2010-01-13 Wed 17:46> Starting after another break
  Restarting the work again after coming back from home. The listing for
  connectivity is below (embarassed by questions about connectivity from
  Elisha Moses: but I realized why I could not remember the connection
  probability - there was none precisely: it was just the number of
  pre-synaptic neurons for each type of neuron):

  Superficial RS 50 -> 1 Superficial RS 
  Superficial RS 50 -> 1 Superficial FRB
  SuperficialRS 50 -> 1 Superficial Basket 
  SuperficialRS 90 -> 1 Superficial Axoaxonic 
  SuperficialRS 90 -> 1 Superficial LTS Interneuron 
  SuperficialRS 3 ->  1 SpinyStellate 
  SuperficialRS 60 -> 1 Tufted IB Pyramid 
  SuperficialRS 60 -> 1 Tufted RS Pyramid 
  SuperficialRS 30 -> 1 deep basket
  SuperficialRS 30 -> 1 deep axoaxonic
  SuperficialRS 30 -> 1 deep LTS
  SuperficialRS 3 -> 1 nontufted RS pyramid
  SuperficialRS 0 -> 1 TCR
  SuperficialRS 0 -> 1 nRT

  Superficial FRB Pyramids
  5 -> Superficial RS
  5 -> Superficial FRB
  5 -> Superficial Basket
  5 -> Superficial Axoaxonic
  5 -> Superficial LTS
  1 -> Spiny Stellate
  3 -> tufted IB
  3 -> tufted RS
  3 -> deep basket
  3 -> deep axoaxonic
  3 -> deep LTS
  1 -> nontufted RS
  0 -> TCR
  0 -> nRT                      


-- I realize that this is basically a matrix with cell types as rows and
columns. How to represent this in NeuroML?

|               | supRS | supFRB | supBasket | supAxoaxonic | SupLTS | SpinyStellate | tuftedIB | tuftedRS | deepBasket | deepAxoaxonic | deepLTS | nontuftedRS | TCR | nRT |
|---------------+-------+--------+-----------+--------------+--------+---------------+----------+----------+------------+---------------+---------+-------------+-----+-----|
| SupRS         |    50 |     50 |        90 |           90 |     90 |             3 |       60 |       60 |         30 |            30 |      30 |           3 |   0 |   0 |
| SupFRB        |     5 |      5 |         5 |            5 |      5 |             1 |        3 |        3 |          3 |             3 |       3 |           1 |   0 |   0 |
| SupBasket     |    20 |     20 |        20 |           20 |     20 |            20 |        0 |        0 |          0 |             0 |       0 |           0 |   0 |   0 |
| SupAxoaxonic  |    20 |     20 |         0 |            0 |      0 |             5 |        5 |        5 |          0 |             0 |       0 |           5 |   0 |   0 |
| SupLTS        |    20 |     20 |        20 |           20 |     20 |            20 |       20 |       20 |         20 |            20 |      20 |          20 |   0 |   0 |
| SpinyStellate |    20 |     20 |        20 |           20 |     20 |            30 |       20 |       20 |         20 |            20 |      20 |          20 |   0 |   0 |
| tuftedIB      |     2 |      2 |        20 |           20 |     20 |            20 |       50 |       20 |         20 |            20 |      20 |          20 |   0 |   0 |
| tuftedRS      |     2 |      2 |        20 |           20 |     20 |            20 |       20 |       10 |         20 |            20 |      20 |          20 |   0 |   0 |
| deepBasket    |     0 |      0 |         0 |            0 |      0 |            20 |       20 |       20 |         20 |            20 |      20 |          20 |   0 |   0 |
| deepAxoaxonic |     5 |      5 |         0 |            0 |      0 |             5 |        5 |        5 |          0 |             0 |       0 |           5 |   0 |   0 |
| deepLTS       |    10 |     10 |        10 |           10 |     10 |            20 |       20 |       20 |         20 |            20 |      20 |          20 |   0 |   0 |
| nontuftedRS   |    10 |     10 |        10 |           10 |     10 |            10 |       10 |       10 |         10 |            10 |      10 |          20 |  20 |  20 |
| TCR           |    10 |     10 |        10 |           10 |      0 |             0 |       10 |       10 |         20 |            10 |       0 |          10 |   0 |  25 |
| nRT           |     0 |      0 |         0 |            0 |      0 |             0 |        0 |        0 |          0 |             0 |       0 |           0 |  15 |  10 |
|               |       |        |           |              |        |               |          |          |            |               |         |             |     |     |









* <2010-01-19 Tue 13:53> Create the Spiny Stellate cells
  There are 240 of them.
* <2010-02-19 Fri 02:17> Trouble with read_proto
  In the current version, I am using read_proto() - class method in TraubCell
  to read the prototype into a class level variable before getting into
  __init__ method of subclass.
  It turns out that when I import the derived class and use it, the __init__
  of TraubCell throws an error saying that prototype does not exist.

  - realized that I was not making copies of the prototype cell in the
    constructor.

  - fixed. 
  - Benchmark: 40 spinystellates connecting to each other

     innerRead: 59 compartments, 539 channels, 53 others

    real	0m10.557s
    user	0m10.390s
    sys		0m0.150s

* <2010-02-19 Fri 23:47> GLview with the model
  I had put a bug report on GLview - the client was crashing.
  It turned out to be my mistake - I was starting the client in glcell mode,
  whereas it should have been glview mode.

  After correcting that, and setting the tick interval for glview to rather
  large value (gldt = 1e-2, plotdt = 1e-3, simdt = 0.025), it shows the
  compartments. 

  But I cannot separate out the cells here: so need some other way to view
  them. Need to investigate how vizpath works: may be I can just see the
  somas?
* <2010-02-27 Sat 01:33> Mg_block with NMDA
  In the model NMDA channel conductance is calculated according to Jahr and
  Stevens, 1990: the same code as Traub et al 1994.

  The conductance is = c * g(V, [Mg2+]) * S(t)

  where c is scaling constant, g is a function specified in Jahr and Stevens,
  1990 and S(t) is time dependent: linearly rises for 5 ms and decays with a
  time constant = 150 ms( Traub et al 1994) [ specified for each cell type in
  Traub et al 2005 ]. I tried to match it with Mg_block implementation in
  MOOSE - but does not seem to have as many terms. 

  Today I got the synaptic channel code / data specification done. I was
  considering netCDF4-python and hdf5 for storing the model data - but they
  seemed too complicated for a simple 2-D dictionary. My code is having a lot
  of data. 

  synapse.py contains the tau and gbar values for each pair of pre- and
  post-synaptic cell types.

  In population.py I enhanced the Population class to lookup the tau and gbar
  and use that for setting up all three kinds of synapses in the same connect
  method.

  With this the spontaneous oscillation with 40 spiny stellate cells is gone -
  which was present with default excitatory synapse I used for the demo.

* <2010-03-08 Mon 17:58> NMDA Channel
  I have been struggling with NMDA channel. The two versions in FORTRAN and
  NEURON look rather different in terms of handling the linear component.

! NMDA part
        if (delta.le.5.d0) then
       gNMDA_suppyrRS(k,L) = gNMDA_suppyrRS(k,L) +
     &  gNMDA_suppyrRS_to_suppyrRS * delta * 0.2d0
        else
       dexparg = (delta - 5.d0)/tauNMDA_suppyrRS_to_suppyrRS
          if (dexparg.le.5.d0) then
          z = dexptablesmall (int(dexparg*1000.d0))
         else if (dexparg.le.100.d0) then
          z = dexptablebig (int(dexparg*10.d0))
         else
          z = 0.d0
         endif
       gNMDA_suppyrRS(k,L) = gNMDA_suppyrRS(k,L) +
     &  gNMDA_suppyrRS_to_suppyrRS * z
        endif
c Test for NMDA saturation
       z = NMDA_saturation_fact * gNMDA_suppyrRS_to_suppyrRS
       if (gNMDA_suppyrRS(k,L).gt.z)
     &  gNMDA_suppyrRS(k,L) = z
! end NMDA part

  NEURON code:

NET_RECEIVE(weight (uS)) {
	if (flag>=1) {
		: self event arrived, terminate ramp up
	: remove one event's contribution to the slope, k
		k = k - weight/time_interval
	: Transfer the conductance over from A to B
		B = B + weight
		A = A - weight
	} else {
		: stimulus arrived, make or continue ramp
		net_send(time_interval, 1) : self event to terminate ramp
	: add one event ramp to slope k:
		k = k + weight/time_interval
:	note there are no state discontinuities at event start since the begining of a ramp
:	only has a discontinuous change in derivative
	}
}


   So I understand that the NEURON code puts a self event for end of linear
   rise of legand gated component (at time = tau1 = time_interval). When this
   event happens, i.e., the exponential decay of the legand gated component
   starts, the weight(conductance) is transferred from A to B.

   The FORTRAN code has no sense of events. So it checks if current time is
   within the linear rise period (5 ms) and if so, it calculates:

   g += g_cell1_cell2 * delta  / tau1 [tau1 = 5 ms]

   Otherwise, it calculates the decay as:

   g += g_cell1_cell2 *exp((tau1 - delta) / tau2) where tau2 is the decay time
   constant.

   Looks like the FORTRAN code is using Forward Euler method, but I am not
   clear about NEURON.

   MOOSE SynChan uses exponential Euler method, but again I am not clear about
   how it is coming to the difference relation from the double exponential
   formula.


   - My implementation simulates self-events in NEURON by maintaining a
     separate queue of old events, which pop out when they are ripe and
     transfer the conductance from A (x_ in my code) to B_ (y_ in my code).

     I am assuming gNMDA_suppyrRS_to_suppyrRS is weight of the synapse from
     SupPyrRS to SupPyrRS and gNMDA_suppyrRS is the Gk_ for the channel.

* <2010-03-19 Fri 16:57> Busy with NMDAChannel
  I have implemenetd the NMDAChan class in MOOSE to emulate the NMDAChannel by
  Jahr and Stevens, 1990 and as implemented by Traub et al. Did not do a
  proper test/comparison with NEURON.

  Upi advised me to leave this out and use the regular SynChan with regular
  MgBlock as this much detail may not be relevant.

  I also found a paper by Destexhe, Mainen and Sejnowski (1994) and chapter 1
  of Methods in Neuronal Modleing (2nd ed) edited by Koch and Segev, which was
  written by the same three authors in 1998. This model solves the issue of
  quick succession of incoming pulses to synapse.

  No matter whether I use NMDAChan or SynChan with MgBlock, I'll have to
  compare the behaviour with the NEURON model.

* <2010-03-22 Mon 19:59> Testing NMDAChan
  - py/test_nmda.py
  - nrn/test_nmda.hoc

  I suspect the weight factor might pose some problem.
  Once this is done I'll be fully ready to start the network. 
  
  The issues: 
  - whether to test the network against neuron or just go ahead.
  - gap junctions - I have not done anything about them.
  - ectopic current injection: not sure what this means physiologically.

    
* <2010-03-25 Thu 10:53> NMDAChan done
  Finally fixed the NMDAChan class - I had mixed up the terms in the equation
  for unblocked Mg, also I had confused dt with tau - (in the neuron code they
  cryptically call it time_interval).

  Now everything works and I committed the fix and the test scripts - both in
  hoc and python.

* <2010-03-29 Mon 09:30> Setting up the connections
  SynChan has this awkward behaviour that the synaptic connections don't get
  updated until reset call. This forces one to set up the connections while
  creating the model, make a reset call and then set the delays and weights
  later. But delays and weights are easiest and most intuitive to access when
  I am looping through different cells/populations.

  The other way will be fortran-like programming, where one does all of the
  setup except setting delays and weights, then going through all the
  populations once again and setting the weights and delays. This also
  requires me to maintain a list of all the SynChan objects and pre and post
  synaptic cell type information.

  - Turns out the setDelay and setWeight methods do updateSynapse. Only
    getNumSynapse does not return the latest synapse count. So using it one
    incremented works.

  - I just fixed getNumSynapse to call updateSynapse so that we get a value
    consistent with the actual number of connections.

  - Now, one funny thing about the synaptic connections is all the synapses
    are between the same pair of compartments.

    The code is like:
    pre = pre_synaptic_compartment
    post = post_synaptic_compartment
    make_AMPA_synapse(pre, post)
    make_GABA_synapse(pre, post)
    make_NMDA_synapse(pre, post)

    Which is something I do not expect physiologically.

* <2010-03-29 Mon 19:36> Created a test for AMPA synapse
  In the process I learnt that Traub uses the alpha function

  (t-t0) * exp(-(t-t0)/tau)

  for which the peak conductance becomes: tau * exp(-1)
  
  After set Gbar to this value, it works fine.

  I was initially breaking my head over a square pulse appearing as gAMPA -
  but turned out that I forgot to set clock 1 to simdt, while I did that for
  clock 0.

* <2010-03-30 Tue 11:42> GABA channel
  Just like AMPA synapse, GABA_A channel for all the synapses, except for
  those made by nRT cells, have the time course:

  g = c * exp(-t/tau)

  For nRT neurons:

  g = c1 * exp(-t/tau_fast) + c2 * exp(-t/tau_slow)

  So, if we set tau_slow = 0, then MOOSE SynChan can handle this. But it
  cannot actually handle 0 values for tau, so I modified SynChan to take care
  of that (without breaking the regular behaviour).

  Also, the double exponential is implemented as two synchans with tau1 =
  tau_fast and tau2 = tau_slow respectively (the regular GENESIS/MOOSE synchan
  does not allow for arbitrary c1, c2 and tau1, tau2, c1 and c2 are tied with
  tau). This is same approach as the NEURON model.

  

* <2010-03-31 Wed 10:14> Small network of SpinyStellate cells
  I think Spiny Stellate cells are worthy of studying by themselves.

  I am setting the reversal potential for GABAergic synapses: I was not clear
  about what are the GABAergic cells. Although the text does not list them
  explicitly, I worked backward from the code and figured this: All cells have
  an e_gaba_a in the cell template of neuron version of the model:
  - nRT:		-75e-3 V
  - SupBasket:		-75e-3 V
  - SupAxoaxonic:	-75e-3 V
  - SupLTS:		-75e-3 V
  - SupBasket:		-75e-3 V
  - SupPyrFRB:		-81e-3 V
  - SupPyrRS:		-81e-3 V
  - DeepBasket:		-75e-3 V
  - DeepAxoaxonic:	-75e-3 V
  - DeepLTS:		-75e-3 V
  - SpinyStellate:	-75e-3 V
  - NontuftedRS:	-75e-3 V
  - TuftedIB:		-75e-3 V
  - TuftedRS:		-75e-3 V
  - TCR:		-81e-3 V

  From the list of time constants in the paper:
  FS, basket, LTS, nRT are sources of GABAergic synapse.

  From the connection set-up in groucho.hoc, these are the pre-synaptic cell
  types for GABA synapse: 
  - Superficial Axoaxonic
  - Superficial Basket
  - Superficial LTS
  - Deep Axoaxonic
  - Deep Basket
  - Deep LTS 
  - nRT

    - This is also confirmed by the list of g_gaba values.

* <2010-04-05 Mon 17:26> Info on population-to-population connectivity
  For debugging purposes and for understanding the syatem from a biological
  point of view it will be useful to have a gross estimate of various kinds of
  synapses. So I have put in a field called syncount in Population which is a dict of dicts
  maintaining, for each kind of post-synaptic cell, count of each kind of
  synapse.

  It is like :
  
  pre.syncount[post][synapse_type] = count
* <2010-04-08 Thu 12:12> Setting up for big network
  I fixed quite a few minor mistakes (like forgetting to set EGABA for LTS
  and Basket cells). Now I am setting up chikki for a big simulation.
* <2010-04-10 Sat 14:07> Bottleneck with copy
  As posted in blog, Niraj pointed out that making copies of cells slows down
  as number of cells increase. The following code snippette:
  \begin{verbatim*}

    for ii in range(cellcount):
        start = datetime.now()
        cell = moose.Cell(proto, 'cell' + str(ii))
        end = datetime.now()
        delta = end - start

   \end{verbatim*}  

   Creates 100 copies of a cell and on my laptop, the first copy takes 17 ms
   whereas the 100-th copy takes 1.32 s. I checked that my python code only
   adds an overhead: 
   just copy takes 5 minutes for 100 spiny stellate cells.
   SpinyStellate constructor takes 17 minutes for the same.


   One solution I can think of is avoiding creating wrappers except for the
   necessary components - pre and postsynaptic compartments, Ca and
   Ca-dependent channels.


   Niraj also suggested that I can avoid the Ca - Ca-dep-chan wrapping if I
   create an additional message (the GENESIS way) which both I and Upi agree
   that is not an elegant solution.


  Upi said we should discuss this later - as it seems to be a common problem
  we are facing.

* <2010-04-12 Mon 10:14> Updating code to reduce python-loops.
  I am going to update the cell models to avoid loops in python. Also avoid
  copy and use readcell for all cells.

  This will involve:
  1. addmsg1 for Ca_conc objects and Ca_conc depenednet channels.
  2. adding a spike element in the cell prototype file for the presynaptic compartment.
  3. no wrapper for compartments unless required absolutely. It will be mostly
     coded in strings. CON: this can make the code really ugly, defeating the
     purpose of using python.

  1. It did not work - although addField adds a field, addmsg1 does not seem
     to work for setting up connection.

* <2010-04-14 Wed 19:58> Fixed the issue for (1) 
  of <2010-04-12 Mon 10:14>

  This turned out to be due to a dependency on GenesisParser
  (Shell->ReadCell->GenesisParser) which is disconnected from Shell, so the
  message to call Shell.addMessage() was getting lost - the actual addmsg
  never happenning.
  
     
* <2010-04-24 Sat 11:29> Transformed SpinyStellate
  I made changes in the TraubCell class in cell.py to avoid creating wrappers
  for all objects and accessing compartments on demand.

  Also the adding Ca2+ messages bit has been moved to prototype files by
  adding field addmsg1 to CaConc and KCaChan objects.

  The autoscheduling has been disabled (made changes in moose code for this) -
  which rescues the cell-creation performance bottleneck.
  
  I am going to run it on ghevar.
* <2010-04-26 Mon 00:03> Bogged down by MOOSE issues
  Compilation of the system on ghevar was a pain (had to compile and install
  swig, python2.6.5, numpy. failed to install pylab (the compilation failed
  because of absence of the font libraries - I am unwilling to do a whole
  GNOME rebuild to satisfy all the requirements). Managed gsl from
  kb.centos.org.

  But latest updates on HSOlve has broken something. Yesterday I tried without
  a proper update - so the clocks were not being assigned properly. Today
  after updating and recompiling pymoose, running spinystellate.py aborts with
  the following message just after reset:

  python: HSolveInterface.cpp:100: void HSolveActive::addInject(unsigned int, double): Assertion `index < inject_.size()' failed.
..Aborted


 I had not registered Niraj's mail about HSOlve scheduling being changed. Now
 I have to check if following his way of scheduling avoids this issue.

 - did not help. And this is independent of autoscheduling.

 
* <2010-04-26 Mon 16:32> HSolve problem fixed
  I discussed the assertion failure with Niraj and he figured that this the
  result of fixing a bug that did not exist. Once he reverted this bit of
  code, the program ran fine.

  The next point I had been missing was that HSolve gets created only at
  reset(). So when I was calling useClock on HSolve on the scheduling code,
  the targets were non-existent. Once I moved the HSolve scheduling beyond the
  reset call, SpinyStellate output became similar to that with autoscheduling
  on.

  Now with SupPyrRS I am facing problem - there are periodic rather long
  bursts compared to a few spikes close togetehr.

  Need to see if there is something with the ion channels.


* <2010-05-07 Fri 12:09> SupLTS fixed
  I had renamed CaT_A in all the files having it into CaT thinking that the
  CaPool has to have the correct value for addmsg1 field in order to connect
  to the Ca2+ current. This caused CaT channel from /library being inserted
  into the compartments instead of Cat_A. The CaPool is supplied by CaL and
  not CaT, so my worry was baseless. Now after changing it back to CaT_A, all
  is well.
* <2010-05-07 Fri 16:50> TuftedIB working but problem with TuftedRS
  TuftedIB started working after fixing X value for AR channel. 

  But TuftedRS is slightly off. I went back to the original plots with
  MOOSE. And there also it is not exact match.

  -- SOLVED : When I zoomed into the beginning of the plots I realized the
  initVm was deviating. The problem is I have set ELEAK instead of EREST_ACT
  in the .p files.
* <2010-05-27 Thu 15:12> Some statistics for Upi's presentation:

  | CellType                  | cell count | compartments/cell | channels/cell |
  |---------------------------+------------+-------------------+---------------|
  | spiny stellate            |        240 |                59 |           539 |
  | deep axoaxonic            |        100 |                59 |           283 |
  | deep basket               |        100 |                59 |           283 |
  | deep LTS                  |        100 |                59 |           501 |
  | nontufted RS              |        500 |                50 |           448 |
  | nRT                       |        100 |                59 |           607 |
  | superficial axoaxonic     |         90 |                59 |           283 |
  | superficial basket        |         90 |                59 |           283 |
  | superficial LTS           |         90 |                59 |           607 |
  | superficial pyramidal FRB |         50 |                74 |           772 |
  | superficial pyramidal RS  |       1000 |                74 |           772 |
  | thalamocortical relay     |        100 |               137 |          1345 |
  | tufted IB                 |        800 |                61 |           594 |
  | tufted RS                 |        200 |                61 |           594 |
  |---------------------------+------------+-------------------+---------------|
  |                           |            |                   |               |
  
* <2010-06-22 Tue 17:36> Save the connectivity matrix separately?
  I am thinking of putting some code just to save the connectivity matrix
  (after the actual cell-to-cell and comp-to-comp connectivity has been
  obtained from the probabilities) - to look for motifs.

  This can be used to select cells to record data from.
  It will be useful to expand the model without actually creating the objects
  and making a string based model structure.
* <2010-08-05 Thu> Another restart
  Getting back to science after five weeks of MOOSE GUI.
* <2010-08-08 Sun 23:01> Support for network
  I decided to use networkX (http://networkx.lanl.gov) for easy handling of
  the network. There several candidate graph libraries: pygraph, networkx,
  igraph. I saw recommendations for all of these in the Python Graph API
  (PEP-like) page, but it seems not only networkx is one of the most popular
  packages with good support, but it is also recommended by the developers of
  several discontinued python-graph-module projects. Its winning point is good
  documentation and ease of use. Although I saw complaints about speed, the
  latest version seems to have improved a lot.
  

  For using networkX, I installed python-graphviz and libgv-python which
  allows one to visualize the graphs in graphviz. It can also utilize
  matplotlib to directly display the graphs.

  
* <2010-08-09 Mon 12:26> igraph -- idiosyncrasies
  As the display of arrow heads is ugly (just a thicker end of the edge) in
  networkX I decided to experiment with igraph a bit. It is a C library with
  Python and R interfaces. Also, display is done via python-cairo bindings.

  I stumbled around a bit before getting started - it lacks in
  documentation. The best I found for the Python wrapper was this:

  http://www.cs.rhul.ac.uk/home/tamas/development/igraph/tutorial/tutorial.html

  The auto-generated API reference is not of much use for a beginner. Things
  are slightly unintuitive. For example, you cannot directly access an edge by
  specifying the vertices: you have to go via select() method for selecting a
  set of edges based on criteria. Also, there is only one graph class which
  incorporates digraph and undirected graphs as well  as multigraphs. 
  
  I was expecting that an empty constructor will create an empty graph, but in
  fact it creates a graph with a single node. The nodes are just integer
  labels and one has to add sepearate attrributes. One cannot add attributes
  when adding an edge - at least there is nothing like that in the docs. The
  add_edge function returns the whole graph and not the newly created edge.

  These are rather inconvenient in Python. But I guess they reflect the c-ness
  of the underlying library.

* <2010-08-10 Tue 13:42> Cleaning up igraph code
  Decided to clean up the code by removing the test code for igraph.
  Converting TraubNet class in connections.py into networkx based code in
  traubnet.py
  
* <2010-08-13 Fri 16:16> networkx better than igraph.
  Added a version of traubnet using igraph. Performance is slightly better in
  networkx (~12 s to build the cell_graph compared to ~16s in igraph).

  I think this is because of extra complexity in Python code to access
  vertices and edges by integer ids instead of vertex labels.

* <2010-08-13 Fri 23:13> Confused about performance
  When I tried using the info() method of networkx to print graph properties
  it took for ever and threw an error: turned out to be a bug in networkx
  (needed to modify:
  /usr/local/lib/python2.6/dist-packages/networkx/classes/function.py

  in line 267: info+="Average out degree: %8.4f\n"%\
                    sum(G.out_degree().values())/nnodes

  changed to (parentheses around format string):		    

  info+="Average out degree: %8.4f\n"%\
                    (sum(G.out_degree().values())/nnodes)

  After this correction, the running traubnet.py to get info tool ~19
  minutes. This shocked me. In earlier runs I had igraph and networkx both
  performing at ~15 seconds.

  Later when I ran it again now, the run time is back to few secods, in stead
  of minutes. Might have been some strange slowdown of my laptop. The printed
  info from traubnet.py:

Name: 
Type: MultiDiGraph
Number of nodes: 3560
Number of edges: 662210
Average in degree: 186.0000
Average out degree: 186.0000

Saved cell-to-cell connectivity datat in cell_graph.gml

real	0m24.788s
user	0m19.200s
sys	0m0.750s

The log file has bench mark data:

2010-08-13 23:08:35,127 INFO traub2005.benchmark traubnet.py _make_cell_graph: Built cell_graph programmatically - time: 11.9645 s


The info from igraph version:

3560 nodes, 662210 edges, directed

Number of components: 1
Diameter: 3
Density: 0.0523
Reciprocity: 0.0266
Average path length: 1.9966
Saved cell-to-cell connectivity data in cell_graph.gml

real	0m36.503s
user	0m34.320s
sys	0m1.650s


Benchmark log:

2010-08-13 23:22:25,009 INFO traub2005.benchmark igraph_traubnet.py _make_cell_graph: Built cell_graph programmatically - time: 15.4138 s


It turns out that reading the gml file takes much longer than generating the
graph in memory.

2010-08-14 00:08:32,281 INFO traub2005.benchmark traubnet.py _make_cell_graph: Read cell_graph - time: 1226.49 s

For reading gml file, igraph has much better performance:

2010-08-14 00:19:08,712 INFO traub2005.benchmark igraph_traubnet.py
_make_cell_graph: Read cell_graph - time: 4.41406 s

And stdout:

3560 nodes, 662210 edges, directed

Number of components: 1
Diameter: 3
Density: 0.0523
Reciprocity: 0.0273
Average path length: 1.9965
Saved cell-to-cell connectivity data in cell_graph.gml

real	0m29.543s
user	0m24.950s
sys	0m0.620s


Confirmed the issue to be the text reading in Python. If I use pickle format
networkx works fast.

* <2010-08-24 Tue 10:40> Virtual network
  Aditya gave me the right word for what I am trying to do with networkx: I am
  creating a virtual network. And yes, to some extent this reinventing the
  wheel, as Upi says. But I cannot wait till the wheel is invented by the
  community. Aditya is looking at possiblities of using neuroML/9ml for
  network specification, but facing enough issues.

* <2010-08-25 Wed 14:20> Performance of various formats
  Here is benchmark of various formats of writing the graphs:

  Name: CellGraph
  Type: MultiDiGraph
  Number of nodes: 3560
  Number of edges: 673610
  Average in degree: 189.0000
  Average out degree: 189.0000

  %MEM: 68.4
  real	11m24.556s
  user	13m47.740s
  sys	0m16.450s
  Saved cell graph in file networkx_cell_graph.yaml of type yaml in 668.958 s

  %MEM: 24.5
  real	1m15.044s
  user	1m12.530s
  sys	0m1.450s
  Saved cell graph in file networkx_cell_graph.pickle of type pickle in 58.4482 s

  %MEM: 15.9
  real	0m32.638s
  user	0m31.890s
  sys	0m0.700s
  Saved cell graph in file networkx_cell_graph.edgelist of type edgelist in 17.3055 s

  In all these I am creating the cell-to-cell connectivity graph from scratch
  and it takes 11-12 s.
* <2010-08-27 Fri 23:35> Visualization
  I ended up using Mayavi 2 to do the 3d visualization. The complete cell-cell
  graph literally looks like a hairball (which Upi found very exciting) using nx.spring_layout. I
  tried shell_layout - but it does not work for 3D, nor does
  circular_layout. spectral_layout works for a 0.1 times the number of nodes
  and edges, but gives the exception:

  Traceback (most recent call last):
  File "traubnet.py", line 494, in <module>
    test(sys.argv)
  File "traubnet.py", line 489, in test
    net.plot_cell_graph_3d()
  File "traubnet.py", line 418, in plot_cell_graph_3d
    pos = nx.spectral_layout(numeric_graph, dim=3)        
  File "/usr/local/lib/python2.6/dist-packages/networkx/drawing/layout.py", line 438, in spectral_layout
    A=A+np.transpose(A)
  File "/usr/lib/python2.6/dist-packages/numpy/core/fromnumeric.py", line 399, in transpose
    return transpose(axes)
TypeError: transpose() takes exactly 1 argument (2 given)

The documentation for this layout says: Position nodes using the eigenvectors
of the graph Laplacian.

I have to read-up what graph Laplacian means!

Next option is random layout and I doubt if it will be far from hairball.

* <2010-08-28 Sat 18:29> Faced with Mayavi bug
  I tried to generate the 3D pictures of the network model on ghevar over
  ssh X forwarding (-Y). Funnily, this was causing my Xwindows to crash. When
  I used ssh without -Y, it gave DISPLAY not found error as expected. After
  trying the code on my system with mlab.options.offscreen = True, I faced
  this error:

  The program 'python' received an X Window System error.
  This probably reflects a bug in the program.
  The error was 'GLXBadContextTag'.
  (Details: serial 120 error_code 170 request_code 153 minor_code 5)
  (Note to programmers: normally, X errors are reported asynchronously;
   that is, you will receive the error a while after causing it.
   To debug your program, run it with the --sync command line
   option to change this behavior. You can then get a meaningful
   backtrace from your debugger if you break on the gdk_x_error() function.)

   This is a known bug: https://svn.enthought.com/enthought/ticket/1824

   Caused enough waste of time.
* <2010-09-14 Tue 09:47> Upi and Oliver pointed out neuron-morphology generation
  Upi mentioned Mark Ha"user's work in Lab meet and then Olver pointed out
  this paper where they show algorithmic generation of most neuronal
  morphologies: 
  
  Cuntz H, Forstner F, Borst A, Ha"usser M (2010) One Rule to Grow Them All: A
  General Theory of Neuronal Branching and Its Practical Application. PLoS
  Comput Biol 6(8): e1000877. doi:10.1371/journal.pcbi.1000877

  I am yet to read the paper and see if it is worth the effort.

  I redid the benchmarking for GML in networkx. Filed a ticket in networkx
  tracker.
* <2010-09-16 Thu 14:58> A test for full model generation vs only graph generation
  I tried to see how slow/fast the creation of the complete model was. I tried
  running it on ghevar: it started taking up to 4 GB RAM and competed with
  Upi's copies of MOOSE running on it. So I terminated it.

  Tried on my laptop : continued for over 1 hr and 3.7 GB RAM. whereas, just
  using a networkx graph to define the network takes much less (~10-20 s). So
  I shall continue to check the connectivity with graph datastructure.
* <2010-09-17 Fri> Switching to igraph
  I wrote a enhancement request in networkx bug tracker for improving the gml
  reading speed. The response from the networkx developer aric seems to
  indicate that it's up to me to write a gml parser in python (they use
  pyparsing - which is terribly inefficient).

  So I switched to igraph for the time being. This is better for my brain as
  igraph is more c-like and close to the way a computer scientist thinks about
  graph.

  The current issue is I cannot add edges:
  
  ----------------

  Traceback (most recent call last):
  File "ig_traubnet.py", line 133, in <module>
    cell_graph = TraubNet('nx_celltype_graph.gml', scale=scale)
  File "ig_traubnet.py", line 77, in __init__
    self.__cell_graph = self._generate_cell_graph()
  File "ig_traubnet.py", line 122, in _generate_cell_graph
    self.__cell_graph.add_edges(edge_list)
TypeError: sequence elements must be integer pairs


   ----------------

   I am trying to make an edgelist first and the call add_edges. Not sure why
   this error is coming up.
* <2010-09-17 Fri 16:53> Fixed the above issue
  The reason for the issue above was the randint() function in numpy returns a
  nupy specific int64 instance, which is not recognized by igraph. After
  converting that to int it works.

  Now the igraph version takes ~ 9s to generate the cell-cell graph. Not a
  remarkable improvement when considering the dict based networkx version (~13
  s). However, the memory consumption is about half that of networkx (390
  MBfor igraph, 870 MB for networkx).

* <2010-09-23 Thu 00:18> lazy attempt to write a gml parser and back to igraph
  I spent couple of hours to write a simple parser for GML files that can used
  for speeding up networkx gml file reading. But after ~50 lines of code in 2
  hrs I realized that it is nontrivial to write a generic parser for this -
  and even if I could parse the graph structure in a dict of dicts relatively
  easily, I would have to convert this dict to networkx graph. Also, as a
  generic format, GML syntax is not very cleanly defined (the BNF grammar in
  the original document is not self-contained and looks sloppy (like the
  definition of real - which is obviously incomplete).
* <2010-10-01 Fri 20:23> Handcoding a hard-copy of the synaptic tau-s and g-s.
* <2010-10-04 Mon 17:14> Handcoded Hardcopy of synaptic taus and gs.
  The summary of celltype graph and cell graph respectively:

  14 nodes, 135 edges, directed

  Number of components: 1
  Diameter: 3
  Density: 0.7418
  Reciprocity: 0.6986
  Average path length: 1.3462

  3560 nodes, 630160 edges, directed

  Number of components: 191
  Diameter: 3
  Density: 0.0497
  Reciprocity: 0.0244
  Average path length: 2.0104

  Why is the number of edges 630160? With the earlier cell graph it was:
  618560!!

  The non-hardcoded version gives the following:

  14 nodes, 135 edges, directed

  Number of components: 1
  Diameter: 3
  Density: 0.7418
  Reciprocity: 0.6986
  Average path length: 1.3462

  3560 nodes, 618560 edges, directed

  Number of components: 191
  Diameter: 3
  Density: 0.0488
  Reciprocity: 0.0250
  Average path length: 2.0031

  I think I had checked the pre-post ratio correctly!


* <2010-10-04 Mon 22:28> The no. of edges becomes 123 when empty allowed_comp list for a pair of celltypes is considered to indicate no-connection,
  Although allowed_comps list is empty, it may indicate axo-axonic / gap
  junction connection. So I should not use empty allowed_comp to exclude an
  edge.

  - Turned out that I had messed up the no. of nontuftedRS and DeepBasket
    cells - as in the list of cell counts nontuftedRS comes before deep basket
    but in description of the synapses nontuftedRS comes after other deep
    pyramids (before TCR and nRT). After fixing this, even the hardcoded
    version has 618560 edges.

  - One notable point is that I am ignoring gap junctions when setting up
    cell-cell connectivty, or skipping an edge when the postsynaptic allowed
    compartment list is empty - this included the connections from axoaxonic
    cells - as for them the target compartment was always axon  initial
    segment: and hence no separate list of allowed comp. 

  - After checking the above, I added single entries for the axon initial
    segement by looking at groucho.hoc for all axoaxonic->glutamatargic cell
    in the allowed_comps list. 

  - Checked if the random number generator selects this single entry every
    time: yes, numpy.random.randint(low=0, high=1, size=(m,n))
    always returns an mxn matrix of 0-s.

  - Now the summary of the network is:
    Celltype-graph
    --------------------
    14 nodes, 135 edges, directed

    Number of components: 1
    Diameter: 3
    Density: 0.7418
    Reciprocity: 0.6986
    Average path length: 1.3462
    
    Cell-graph
    --------------------
    3560 nodes, 662210 edges, directed

    Number of components: 1
    Diameter: 3
    Density: 0.0523
    Reciprocity: 0.0270
    Average path length: 1.9966
    
* <2010-10-05 Tue 16:00> I(h) or g(AR) issue
  Just came across a paper: Dendritic Spikes in Apical Dendrites of
  Neocortical Layer 2/3 Pyramidal Neurons by Matthew Evan Larkum, Jack Waters,
  Bert Sakmann, and Fritjof Helmchen [The Journal of Neuroscience, August 22,
  2007, 27(34):8999-9008; doi:10.1523/JNEUROSCI.1717-07.2007]

  This paper says the I(h) conductance is much less in superficial pyramidal
  cell dendrites compared to layer 5. But in Traub model it is the reverse: in
  layer 2/3 it is ~0.25 nS, whereas in deep layers it is ~0.1 nS.

  Also, I am a bit worried about gap junctions: not handled by hsolve, nor can
  I use GENESIS style raxial setting to simulate them in MOOSE.
* <2010-10-11 Mon 18:18> Switching network description to another file:
  I started putting together the network description in trbnet.py. This should
  be my final version, after scattering several experimental versions in
  traubnet.py, ig_traubnet.py and network.py.

  The conclusion is: keep the explicit datastructure for full network.
  
  have a celltype-celltype graph for pretty picture and quick conversion to
  other forms.

  generate cell-cell graph only for pictures. Otherwise generate the network
  straight from the celltype-celltype graph.
* <2010-10-22 Fri 23:02> Data storage and analysis ... HDF5? 
** Upi's code
   Yesterday I had a discussion with Upi and for data analysis and storage he
   mentioned some code he had written earlier. However I looked around in his
   home directory but could not find anything that looked like
   analysis/compression code. 
   
   I should refer to his paper and go through the methods.

** My additional plans
   I was impressed by Ming Jhou Ding's causality based approach and am
   interested in applying it. I still am picking up the theory of time series
   analysis that he uses (ARIMA, Spectral Analysis), but should accelerate
   towards applying them.

** HDF5 and friends
   In the mean time, I looked at numpy's built-in data saving capabilities and
   pytables' hdf5 format. They take the same amount of space for simple
   arrays. However pytables offers the added advantage of structured
   data. It can be really helpful for organizing the simulation generated data
   as well as the state.

   However it turns out that numpy/hdf5 compression is not optimal in that it
   does not compress the numeric data (100000 x 64 bit float take 800
   KB even if all the entries are same). Obviously, there should be better
   compression for regular data. Upi also mentioned some code he had written
   to compress Vm data. However bzip2 does a good job of compressing data with
   redundancy (an 1.6M npz is compressed to 240K where 50000 entries are
   linearspaced, 150000 are zeros).

   When using compression filters with a 2x10000 CArray, the size actually
   increases to 1.7M (opposed to 1.6M uncompressed).

   - I realized that I was making the mistake of not setting complevel
     parameter to tables.Filters(), which defaulted to 0 (no-compression).

** Discussion with John Jeffereys
   I had a quick discussion with John Jeffereys after his talk today. He is
   collaborating with Roger Traub. But he warned against too complex models
   where the parameter space is not really constrained. 

   I had started with the need for gap junctions to generate gamma
   osicllations - Traub justified them by the fact that they are required in
   the mdoel in order to get the gamma oscillation. Of course this is circular
   logic and John pointed out that it is possible that you cannot rule out the
   possibility that gamma osicllation could be achieved by tweaking other
   parameters in the model without introducing gap junction. But he confirmed
   that interneuron-interneuron gap junctions are very well studied, but not
   excitatory-excitatory ones.

   Also, the difficulty in tracing gap junctions is that pharmacological
   agents that can be used for tracking gap junctions are not very specific.

   If in future people can create markers for connexin/pannexin, then there is
   a possibility. Currently, the evidence for excitatory-excitatory gap
   junction in very thin: one study found 3 in 3000 cell-pair recordings
   (reference?). 

   Also, even without gap junctions, there can be field-based electrical
   coupling between closely located fibres. Our knowledge of gap junctions is
   quite vague at this point.
   

   
   
* <2010-10-27 Wed 01:58> Passed test for trbnet.py::celltype_graph
  Just finished writing the test and fixed all issues with attributes(keys) in
  GML specification (where underscore is illegal). Generated celltype graph
  passes the comparison with that generated bu ig_traubnet.py.

* <2010-11-08 Mon 16:39> TODO: save network info and data in same file.
  As noted in my blog, I should save the network connectivity info and the Vm
  data. One optimization for space could be recording the spike-times.

  But I think recording the Vm and Ca initially is important as I do not have
  much prior knowledge of the data.

  The following info can be usefule for the model:

  1. celltype-graph data (already built into the code) -- will contain tau
     values for each synapse type between each pair of populations.

  2. adjacency list for each of:
     g_gaba
     g_nmda
     g_ampa

     The adjacency lists can be essentially a sparse matrices.

  3. Save the Vm(0.0) and diff(Vm) for each cell. This increases the
     compression efficiency dramatically.
     
  Also, as UPI POINTED OUT, A SIMULATION SHOULD FINISH OVERNIGHT. I have to
  scale my model accordingly.
* <2010-11-09 Tue 14:55> Saving model and data using PyTables.
  I am not sure whether I should keep the network info and the data together
  in the same hdf5 file or separate them into two files.

  Initially I thought keeping them together will add to the integrity of the
  data as the model and data will be staying together.

  Then I thought the program will write the network to the file before
  simulation, but will save data at the end of simulation. Thus there should
  be two files.

  At the end I decided that I should be writing the model and data together at
  the end of simulation.

  But another point could be to save data as soon as it is generated - do not
  delay writing till the last moment.

  What datastructure for the network?

  Adjacency lists containing g values between cells.

  But what should be the form of the adjacency list?

  Assign a 32 bit int to each cell.

  leftmost 8 bits for index into celltype list.  rightmost 8 bits for index
  into poulation list for the same celltype.
  
  but if I try to represent it as a sparse matrix (scipy.sparse.lil_matrix?
  coo_matrix?), the dimension of the matrix will be 2^32 X 2^32. Whereas, if I
  index all the cells sequentially, it will be 3500 X 3500.
  coo_matrix does not allow element access. So that is useless.
  lil_matrix constructor encounters memory error. Thus, I think the fall back
  is dicts.
  
* <2010-11-17 Wed 10:20> Network instantiation

  On my laptop:

  2010-11-17 02:12:19,270 INFO traub2005.benchmark trbnet.py _generate_cell_graph: cell-cell network generation in: 4.76215 s
  2010-11-17 02:39:11,647 INFO traub2005.benchmark trbnet.py create_network: Finished network creation in: 1611.63 s

  On ghevar:

  2010-11-17 10:48:39,070 INFO traub2005.benchmark trbnet.py _generate_cell_graph: cell-cell network generation in: 4.083 s
  2010-11-17 11:07:45,235 INFO traub2005.benchmark trbnet.py create_network: Finished network creation in: 1146.16 s

* <2010-11-17 Wed 20:18> Added code to save model data
  I added a function to save the network structure in a hdf5 file. I debugged
  it till the whole thing ran without error. But saved file does not have
  correct values:

  ggaba - all 0
  
  It had to be set to a numpy array of shape=(2,). This fixed it.
  Now remaining:

  1. Put in a function to read the network model from file and then to compare
     it to the original.
  2. Put in the code to do the simulation itself.
  3. Save the data.
* <2010-11-22 Mon 11:56> What to record?
  Now I have finished the function to test the writing of hdf5 file for the
  network structure by reading it back and comparing the values. Started test
  run.

  Next thing is to decide what to record. 

  1. For a few cells, I would like to see the whole time series of Vm and CaConc. 

  2. For the rest of the cells, I can at least record maintain the spike times.

  I also came cross thsi neuro-timeseries analysis package:
  python-nitime. Going through its manual to see if it will be of any use.
* <2010-11-24 Wed 17:13> Initial version of recording code
  Put in the functions to setup recording on the network.
  
  I am recording full Vm for the 10 cells with maximum degree from each celltype.
  Recording spike times for all cells.

  I also added command line arg handling in trbsim.py --

  -c cellcount-file : will modify the cellcounts

  -s synscale-file : will scale the conductances of synapse types

  -v g-value-file : will set the conductances of specified synapse types

  -t simtime: will set the simulation time (1s default)
* <2010-12-03 Fri 19:49> Got the first run finished
  But it was all spontaneous activity - the stimulus protocol has not been
  implemented yet. 

  However I note some points (considering Upi's paper):

  - Stimulus pattern optimization:
  + background size: 1300
  + probe pulses: 6-7 pulses
  + interpulse interval: 10-20 ms
* [2010-12-10 Fri] Ideas from TCM
  TODO: 

  1. Stochasticity in synaptic release
  2. Better visualization (display the action potentials in a 2D/
     possibly 3D grid as an animation)

  3. Some adaptation of Ising model (Aditya proposed)

     - brainstorming: is 1 s of simulation sufficiently long to find
       out these connectivity patterns?

     - can do a pilot study with a smaller network.

     - can I come up with an analytical approach for cases where we
       have control over stimulus?

     - a pilot study with patterned stimulus will be useful.
* [2011-01-12 Wed] Thalamocortical input
1. Gil, Z., Connors, B. & Amitai, Y. Efficacy of Thalamocortical and
   Intracortical Synaptic ConnectionsQuanta, Innervation, and
   Reliability. Neuron 23, 385-397 (1999).

  - Quantal events from TC and IC synapses were indistinguishable.
  - However, TC axons had, on average, about 3 times more release
    sites than IC axons, and the mean release probability at TC
    synapses was about 1.5 times higher than that at IC synapses.
2. Walmsley, B., Alvarez, F.J. & Fyffe, R.E.W. Diversity of structure and
   function at mammalian central synapses. Trends in Neurosciences 21, 81-88
   (1998).

3. H. Korn and D.S. Faber, Quantal analysis and synaptic efficacy in the
   CNS. Trends Neurosci 14 (1991), pp. 439-445
4. V.N. Murthy, T.J. Sejnowski and C.F. Stevens, Heterogeneous release
   properties of visualized individual hippocampal synapses. Neuron 18 (1997),
   pp. 599-612.

  -- Need to understand relationship between stimulus intensity and release
  probability. In Gil et al, they adjusted the stimulus intensity to give
  around 60% failure. In Dobrunz & Stevens it was 50%. Is there a mapping
  between stimulus intensity and release probability?

* <2011-01-13 Thu 11:00> Wrote to R Angus Silver

  For more release probabilities. 
* <2011-01-20 Thu 10:19> Kohonen network?
  Found this paper on visualizing large number of spike trains:

  Jurjut, O.F. et al. A Color-Based Visualization Technique for Multielectrode
  Spike Trains. Journal of Neurophysiology 102, 3766 -3778 (2009).

  In this paper they described a Kohonen network could be used for looking at
  high dimensional data. The general intro to Kohonen network is available
  here:

  Teuvo Kohonen and Timo Honkela (2007) Kohonen network. Scholarpedia, 2(1):1568
* <2011-05-03 Tue> Wondering about ectopic current
  As I was trying to implement the current injections in Traub model,
  I realized that the process for current injection was funny. The
  magnitude was being flipped between 0.4 and 0.0 based on whether a
  urng was within a small specified interval. Poor-man's Poisson
  process? [It is a binomial distribution with very low p]. Strangely,
  the cells for which this is done are also selected according to a
  random vector.
* <2011-05-07 Sat> Everything seems to be falling apart
  I have been trying to get some simulations executed successfully for the
  whole week without success. I expected spontaneous activity but everything
  remains contsant. Several bug fixes. No solutions yet. Ectopic spikes have
  too long intervals(1-10s) for my simulation time (1s). But out of several
  hundred RandomSpike objects, I expect at least some to appear within the
  first second of simulation: something is seriously wrong.

  Also, Upi's analysis was dependent on paired pulse facilitation, but I don't
  have that incorporated in the model. Also, in cortical network some synapses
  show facilitation, some depression. The behaviour is fairly complex
  (dependent on frequency as well).

* <2011-05-19 Thu 10:21> Fixed most of it. AMPA/NMDA issue
  The spike detection issue was a problem with table and not with
  RandomSpike. Now I have been running simulations in batches throughout last
  week. 

  Implementation of facilitation and depression in synapses yet to be implemented.

  I have been reading Henry Markram's review on Interneurons in Neocortex:

  Markram, H. et al. Interneurons of the neocortical inhibitory system. Nat Rev Neurosci 5, 793-807 (2004).

  According to this, there are no NMDA receptors accompanying the AMPA in case
  of excitatory synapses on to inhibitory interneurons.

* <2011-05-20 Fri 10:37> Finished adding stimulus protocol
  I finished writing the stimulus protocol: it is essentially paired pulses
  for background and with every alternate background stimulus a probe pulse
  pair is applied. The settings for stimulus protocol are saved in a file
  starting with 'protocol_'.
* <2011-06-02 07:24:17> Data Analysis - preliminary
  These are my rough observations by plotting all the spike rasters for each
  cell type. Times are in seconds
** data_20110515_151158_387.h5
*** Deep Axoaxonic cells
    - 2 spikes @ the start (to be ignored as unstabilized system)
    - 1 spike @ 0.275 s
    - 1 @ 0.44
    - @ 0.52
    - @ 0.675
    - @ 0.925
*** Deep Basket cells
    - 2 spikes @ start (ignored)
    - 0.27
    - 0.43
    - 0.52
    - 0.675
    - 0.93 (a few clustered around this points)
*** DeepLTS
    - 0.1 .. 0.2
    - 0.43
    - 0.68
*** NontuftedRS
    - 0 (ignored)
    - 0.675
*** SpinyStellate
    - Unusually perfect allignment of all spikes.
    - 0 (ignored)
    - 0.05
    - 0.078
*** SupAxoaxonic
    - 0.0 and 0.02 (unusually exact alignment - ignored)
    - 0.27
    - 0.43
    - 0.52
    - 0.67
    - 0.93 (a few scattered around)
      
*** SupBasket
    - 0.0 and 0.02 (ignored)
    - 0.27
    - 0.45
    - 0.52
    - 0.675
    - 0.9
*** SupLTS
    - 0.02 (scattered)
    - 0.44
    - 0.675
    
*** SupPyrFRB
    - 0.02 (scattered)
    - 0.43
    - 0.675
*** SupPyrRS
    - 0.0 (ignore)
    - 0.675
*** TCR 
    - Uncannily exact alignment
    - 0.0
    - 0.002
    - 0.02
    - 0.075
      
* <2011-06-09 Thu> Synaptic release probabilities - What is right?
  Angus Silver, Feldmeyer, etc. show that release probabilities in synapses
  between cells in cortical columns are quite high (>0.8). On the other hand
  this older paper says thalamocortical synapses have release probabilities
  that are 1.5 times higher than intracortical synapses. 

  Gill, Konnors and Amitai talk about TC Pr ~0.8 and IC Pr 0.2 (latter
  is not correct according to Feldmeyer).
* <2011-07-18 Mon 15:16> Measuring and interpreting neuronal correlations. Nat Neurosci 14, 811-819 (2011). :TODO:FUTURE:

  1.Cohen, M.R. & Kohn, A. Measuring and interpreting neuronal
  correlations. Nat Neurosci 14, 811-819 (2011).

  One possible line of work: Study what correlation level is reqiured at
  various measurement durations. 
* <2011-08-30 Tue 14:26> Started deterministic simulation
  After doing several smaller tests with the stochastic version, I started a
  full simulation:

  python2.6 trbsim.py -d 0.25e-3 -p 1e-3 -t 5.0 -x 0.8  2>&1 | gzip -c > nohup_`date '+%Y%m%d_%H%M%S'`.gz

  This was started with _moose.so.debug.20110827

  When I do not use --stochastic flag, the synapses are all deterministic
  ones. This has also the corrections for ggaba and gampa. Earlier I was
  trating the ggaba from nRT as ordinary double exponential synapse, but it
  was actually equivalent to two single synapses. Also, the AMPA was an alpha
  synapse but I was putting it as a single exponential synapse.

  I need multiple realizations of the full simulation for time series
  analysis. Currently, only valid data seems to be from the simulation on
  2010-12-01.
* <2011-09-02 Fri 18:26> Analyzing data - xcorr
  Implemented fft based xcorr using numpy. Created two classes to load the data file and the network file respectively.
  Todo: combine the two classes into a single one so that:

  I can plot xcorr between any pair of cells by index.
  Based on the maximum xcorr, I can tell the paths between the two cells and the weights of the connections.
  
* <2011-09-26 Mon 15:55> TODO list:
  This is a list of tasks to do:
  
  Look at clustering of cells by spike patterns and correlate with real connectivity cluster.

  Thalamic input synchrony (Bruno Sakmann)

  Depth profile of LFP.

  Dataviz: keyboard shortcuts, integrate analysis into it - like correlations.
  Dataviz: provide option for displaying arbitrary data/attributes (like runconfig stuff).


  
* <2011-10-10 Mon 11:58> Blunder in network generation
  I was having issues with funnily wide APs. I pinned it down to mistake while
  randomizing channel conductances. Today I ran one simulation with a small
  network (5 cells each) and aDeepBasket_0 had very funny AP. When I looked at
  the conductances I was saving, I realized that there was self-connection.

  To find the reason I went back to network generation code. And it seems at
  some point I just skipped randomization of the connectivity. The cell-graph
  was not being populated at all and the moose-network generation code was
  just connecting up cells in sequence with no check if two cells were the
  same.

  I suspect this blunder may have entered when I was modifying the code to
  include stochastic synapses.

* <2011-10-10 Mon 12:11> No - it was ok except for a check for self connections
  I realized that although I was going through all cell pairs sequentially,
  when creating synapses I was actually looking up the conductance values from
  the randomized matrix I generated in _generate_cell_graph.
* <2011-10-29 Sat 23:15> Labmeet today
  Notes from Upi uploaded in blog. Trying to ipmlement filters. nitime has a
  nice tutorial:
  http://nipy.sourceforge.net/nitime/examples/filtering_fmri.html

  But the filtered LFP is not very encouraging for spontaneous activity:
  maximum at 17 Hz, no gamma. Need to try with bias currents as Traub
  mentioned.
  -------------------

** Notes from Upi after Lab meet presentation:
   - TuftedIB - check if bias or bursting affects network behaviour.
   - DeepLTS - is the spiking locked to the field? Also other populations.
   - Calcium response difference: check channels (CaL, CaT). check literature to see if sme are known to have small Ca signals.
   - Check distribution of synaptic conductances - narrow or wide. time evolution - if it has reached steady state.
   - Homeostasis of excitatory/inhibitory balance of plasticity is a big interesting question. Check prior literature. Mark van Rossum. Xiao-Jing Wang, Misha Tsodyks.
   - Filter below 400 Hz LFP to map to experiment. Check LFP spontaneous. Check LFP extent. Consider more spatial info. Consider more complete sampling (of cells and compartments for LFP calculation).
   - Causality and connection John Hertz etc.
   - What are people doing with Traub model?

* <2011-11-03 Thu 22:01> Power Spectrum????
  I have been trying out various approaches to look at the frequency domain of
  the field potential. But as I went into signal processing literature, it
  seems more dubious. While DSP people routinely warn against Fourier
  transform (as it is a poor estimate of power spectrum according
  Wiener-Khinchin theorem)[See the second message here:
  http://www.velocityreviews.com/forums/t666432-frequency-analysis-without-numpy.html],
  KP told me that they just look at Fourier Transform for detecting the
  frequencies.

  I just used nitime module to plot periodogram, FFT, Welch PSD, multitaper
  and each peaks at a different frequency. Now the classification of of the
  EEG rythms will depend on what technique they use.
  
* <2011-11-28 Mon 11:15> Points from Padraig
  Padraig has converted the model to NeuroML 1. But most of the network
  generation is programmatic. So it does not really help. He also pointed out
  that the compartmentalization is not stable. He needs of the order of 1e3
  compartments to get stability. However, we doubt how much that will affect
  the physiological study in our case.

  On the other hand, Mikael Djurfeldt has started a C++ library for generating
  connectivity. This will be interesting to look at.

  I also agreed to work with Yann le Franc on ontology. I can use the Traub
  model as an example. Since current neuroml does not allow arbitrary
  connection rules, I am thinking of utilizing CSA (connection set algebra)
  from Mikael and develope some arbitrary format (based on discussions at the
  INCF task force).

  Essentially, we need the selection sets to uniquely determine populations
  and then use csa to define connections between those populations.
* <2011-11-30 Wed 11:32> Another blunder found
  I was suspicious that none of the SupPyrRS cells were spiking after the
  first spike. When I compared with SupPyrRS I noticed EREST_ACT was -0.065 V
  in the .p file. Compared with hoc code, it should be -0.07
  V. Corrected. Checked other files. Still suspicious about Tufted cells.

* <2011-12-01 Thu 01:18> No blunder, I was wrong that I was wrong
  The GENESSIS docs are vague. I figured that EREST_ACT is what is used for
  setting initVm, ELEAK is what is used for Em. I am not sure if there is an
  issue with spine area multiplication. They are multiplying all dendritic
  ionic conductances and cm by spine_area_multiplier=2. This does not make
  sense as I doubt if the pyramidal cell dendrites have spines. After
  switching the values to original, SupPyrRS seems to fire more decently.
* <2011-12-01 Thu 17:51> Confused about SupPyrRS
  Today I reverted back to spine_area_multiplier=2 and revrted the original
  SupPyrRS.p file. Almost exact match, but the cell is regularly spiking at
  0.4 nA injection.
* <2011-12-03 Sat 14:43> Discussion with Upi
  - Port model to new moose.
  - Once model is settled on, 
    - consider current updates in ChannelRodopsin (stimulus) and gCAMP (read
      out) technologies.
    - consider ChR2 on read-out cells to bring them close to firing.
    - consider what other stimulus patterns can be suitable
    - consider Ising model/ Granger causality.
    - consider what kind of connectivity can we figure out (say for example,
      if there is this kind of connectivity pattern, then we get synfire chain
      or some other phenomenon).
      
* <2011-12-14 Wed 12:02> All single cells re-tested. Running simulation
  Running the simulation with the thalamus excluded. GABA conductance is
  increased 1.25 fold. Bias current of 0.05 nA applied to SypPyrRS, SupPyrFRB,
  SpinyStellate, TuftedIB, TuftedRS and NontuftedRS from the start of
  simulation.
  

* <2011-12-20 Tue 14:45> Stimulus protocol
  Going to start on the stimulus protocol. 
* <2011-12-22 Thu 17:15> Finished stimulus protocol yesterday
  Updated and fixed the stimulus protocol code.
* <2011-12-23 Fri 09:47> Spatial reach of LFP
  Following up on Upi's comment in Lab meet, found this paper:
  http://www.cell.com/neuron/abstract/S0896-6273%2811%2901005-1#Introduction
  Apparently, LFP reaches only a few hundred microns. Should be within the
  range of a single barrel.

  They did a study with L3, 4, 5 at different radial distances from a set of
  recording positions. They found that "95% of the amplitude of the signal
  recorded in the soma layer came from neurons within a radius smaller than
  200 um" for uncorrelated synaptic inputs. Even in case of correlated
  synaptic inputs, the knee of the LFP amplitude curve is within 300 um (fig 4).

* <2011-12-23 Fri 12:21> Intrinsically bursting pyramids
  Franceschetti, S. et al. Ionic mechanisms underlying burst firing in
  pyramidal neurons: intracellular study in rat sensorimotor cortex. Brain
  Research 696, 127-139 (1995).

  Has a detailed study of tufted IB and RS pyramids in Layer V.

  Issues that I note with Traub et al 2005 model when comparing with this study:

  Out of 107 pyramidals, 59 were RS and 48 were IB. But in Traub model we have
  200 and 800 of them respectively.
* <2011-12-24 Sat 12:39> LFP comparison with experimental data
  I was puzzled by the fact that the extracellular field potential I am seeing
  is domiated by 12 Hz wave, whereas Traub et al mention 30 Hz(gamma). But I
  found data on regular spiking units spiking at around 10 spikes/s and lower
  rates in this paper: this paper: Simons, D.J. & Carvell,
  G.E. Thalamocortical response transformation in the rat vibrissa/barrel
  system. J Neurophysiol 61, 311-330 (1989).
* <2012-01-03 Tue 11:02> Small simulations
  Got the data from 20-cell-each simulation. Nothing exciting. Most cell types
  don't fire at all.
* <2012-01-03 Tue 11:03> Mriganka Sur's stuff
  Yesterday Mriganka Sur talked about some really interesting work he is
  doing. It's about local inhibition in cortex by somatostatin neurons and
  parvalbumin neurons. Parvalbumin neurons target soma and somatostatin
  neurons target dendrites. The first one causes a scaling down (division) of
  the the postsynaptic Vm whereas the latter does a subtraction.

  It will be interesting to see whether this is present in Traub model also.
* <2012-01-26 Thu 19:25> Oscillations and its effect
  Buzsaki, G. & Draguhn, A. Neuronal Oscillations in Cortical Networks. Science 304, 1926 -1929 (2004).

  The effect of input depends on the phase of the oscillation. Can we utilize
  this in timing the delivery of the second pulse?

* <2012-01-27 Fri 22:14> Comparing to in vivo recordings
  Simons and Carvell 1989 seems to be the most detailed study of the effect of
  whisker deflection on barrel columns. Need to read this first. They also
  talk about strong inhibition due to whisker stimulation.
* <2012-02-04 Sat 15:39> Million synapse - detecting spiking due to probe
  Issues: the effect in L4 appears after tens of milliseconds, how do I
  associate the stimulus with the spike? Set a time window and any spike
  withing this window after the stimulus as stimulus evoked???

* <2012-02-06 Mon 14:37> How to get what is caused by probe stimulus??
  As a first pass, I am just collecting spike sources that generate at least
  one spike within a given time window after the probe stimulus. Too many
  cells captured under this criterion, including ectopic spike sources. 

  I need to take cells that did not spike in the same interval after the
  bg. Also, how to establish causality between a stimulus and a spike?? A
  single sample can possibly not tell it. Multiple stimulations of the same
  set will cause plasticity changes (for the sake of reducing simulation time
  I am doing a 2 Hz stimulation for 10 s, which is known to cause
  depression/facilitation. Other option could be to reset after each short
  simulation and write out a data file for each one.
* <2012-03-19 Mon 14:56> Analysis to do
  
** Step 1: Probability of post synaptic cell firing within a time window following presynaptic spike
   I did this analysis on set of similar configurations described here
   http://magaj.ncbs.res.in/notepal2012/blogs/subha/2012-03-12

   It turned out that of all the post synaptic cells that fire following a
   presynaptic spike, do so withinin 30 ms. 

   But majority of the postsynaptic cells do not do so (tallest bar is at 0-10
   ms). There is slight increase when I expand the window to 40 and 50 ms.

** Step 1.1: The case for no synapse
   I should also count in how many cases there is a firing within the
   specified timewindow when there is no connection. Thus for cell A, count
   the number of cells B = {b1, ..., bn} that fire within an interval T from
   the spiking time of A such that b[i] is not connected to A.

   I have to do this yet. This will tell me if the postsynptic firing is any
   better indicator of connectivity than random firing.

** Step 2: Probability of presynaptic spike preceding a post synaptic spike
   This is to be done today. In this case, for each post synaptic cell, I
   shall check all the presynaptic cells (I missed this in Step 1). For each
   postsynaptic cell it makes sense to count the total number of spikes from
   all the presynaptic cells within a given time window to the past and
   average over the number of presyanptic cells.
   
* <2012-03-21 Wed 09:09> Result of step 1: negative
  Most of the connected cells simply do not fire following the presynaptic
  cell. Maximum of the probability histogram is at 0. I am going to try
  computing this probability for excitatory cells alone.


* <2012-05-01 Tue 11:03> Have been cracking my head over the delay in spinystellate spikes
  Looks like the inhibition is too high. In reducing the network size, when I
  have only thalamus and L4, the inhibitory:excitatory cell ratio goes very
  high (240 Spiny Stellate, 100 TCR vs 100 DeepLTS, 100 DeepBasket and 100
  DeepAxoaxonic) whereas I see reports that the number of excitatory cells is
  about 10 times that of inhibitory cells. Upi suggested that I increase the
  TCR->SpinyStellate conductance but I have to look for its physiological
  basis.

  I looked at corticothalamic feedback and it seems that only NontuftedRS
  cells give feed back to TCR cells. As I removed NontuftedRS cells (along
  with TuftedIB and TuftedRS) as useless (not spiking in my simulations),
  there is no corticothalamic feedback. Now I am going to try one simulation
  with NontuftedRS put back.
  

* <2012-05-01 Tue 16:48> Number of cells
  WHile browsing through literature I found a confirmation of the fact that
  the inhibitory FS neurons do respond to thalamic stimulus more reliably and
  precisely than Spiny Stellate cells. 

  1.Sun, Q.-Q., Huguenard, J. R. & Prince, D. A. Barrel Cortex Microcircuits:
  Thalamocortical Feedforward Inhibition in Spiny Stellate Cells Is Mediated
  by a Small Number of Fast-Spiking Interneurons. J. Neurosci. 26, 1219-1230
  (2006).

  Also, the number of spiny stellate cells is 240 and according Traub et al
  this is a reduced number. I am trying to figure out the correct number of
  cells in L4. Also, I am thinking of incorporating the star pyramidals in L4
  by removing the spines (which is implemented as doubling of surface area for
  ionic conductances) from some of the spiny stellates.

  The following paper may have something:

  2.Meyer, H. S. et al. Number and Laminar Distribution of Neurons in a
  Thalamocortical Projection Column of Rat Vibrissal Cortex. Cerebral Cortex
  20, 2277-2286 (2010).

  Quoting from them:

  ------------
   The resulting neuron numbers per layer
   in the average column were 63 6 10 (L1), 2039 6 524 (L2), 3735 6
   905 (L3), 4447 6 439 (L4), 1737 6 251 (L5A), 2235 6 99 (L5B),
   3786 6 168 (L6A), and 1066 6 170 (L6B). 
   
   ... ... ...
   
   This yielded 6489 neurons in the supragranular
   layers, 4816 neurons in L4 (4094 spiny L4 neurons when
   corrected for INs), 1194 neurons in L5A (1015 slender-tufted
   pyramidal neurons), 1528 neurons in L5B (1299 thick-tufted
   pyramidal neurons), and 5352 neurons in L6.
   ------------------------


   Since the number of inhibitory cells is ~15% (Lin et al 1985,
   Beaulieu 1993) mentioned in above article, with 300 inhibitory cells, the
   number of excitatory cells should be 300 * 75/15 = 1500. I am switching to
   1000 spiny stellates in next simulation. Keeping the deep pyramidal 0 for
   the time being.


* DONE <2012-05-07 Mon 12:06> scaling synaptic strength
  CLOSED: [2012-05-12 Sat 14:01]
  In last lab meet I discussed the change in spiking behaviour of cell
  populations when the cell counts are reduced. Upi and Aditya pointed out
  that it is a standard practice to increase the synaptic strength to
  compensate for the reduction in the number of synapses. I am not sure what
  to do for the removed L2/3 and L5 and L6 excitatory neurons.

  The simulation of 3 May 2012 showed somewhat weird result: epileptic
  activity in SpinyStellate cells. This had 1000 spiny stellates. But since I
  was using probabilities without scaling, the total synaptic conductance has
  been scaled up due to increase in cell count. On the other hand, Since I
  removed the superficial pyramids, the synaptic conductance for them is not
  there. Not sure what is the right thing to do.

* <2012-05-07 Mon 12:08> Important paper
  Oberlaender, M. et al. Cell Type-Specific Three-Dimensional Structure of
  Thalamocortical Circuits in a Column of Rat Vibrissal Cortex. Cereb. Cortex
  (2011).doi:10.1093/cercor/bhr317

  Discusses detailed 3D reconstruction of the analtomy of the thalamocortical
  pathway.

* <2012-05-10 Thu 16:34> Bias currents issue
  I was applying 0.05 nA bias current injection to all spiny stellate
  cells. Now I cannot find it in the original fortran or neuron code. In the
  paper they mention bias currents of much larger value (0.1 nA or more) for
  specific simulations without ever explaining what these are. But they
  mention in passing that hetergeneity in cells were introduced by applying
  steady bias currents. Now I am going to do a small simulation with all bias
  currents disabled.


* DONE <2012-05-12 Sat 13:57> Optimize dataviz code for displaying data tables.
  CLOSED: [2012-05-18 Fri 15:36]
  - CLOSING NOTE [2012-05-18 Fri 15:36] \\
    implemented the model and incorporated into dataviz.
  CLOCK: [2012-05-16 Wed 10:58]

* DONE <2012-05-12 Sat 15:12> Run full simulation
  CLOSED: [2012-06-15 Fri 10:24]
  - State "DONE"       from "TODO"       [2012-06-15 Fri 10:25] \\
    Today the simulation for 55 s with halved cell count got over: /data/subha/cortical/py/data/2012_05_22/traub2005_20120522_152734_10973.log
  When going through the older simulations to see why I eliminated the deep
  layer pyramids, I saw that there was more activity in these cells in the
  full model (albeit with bias currents). It is possible that we really need
  the full model to complete the network behaviour (for example, now there is
  too much synchronized spiking in spiny stellates and no spiking in between
  these bursts).
* DONE <2012-05-13 Sun 20:59> Running a simulation
  CLOSED: [2012-05-22 Tue 16:18]
  - CLOSING NOTE [2012-05-22 Tue 16:19] \\
    This simulation finished. Documented in labnotebook entry: http://magaj.ncbs.res.in/notepal2012/blogs/subha/2012-05-22
  Supragranular layers removed. Added nontufted RS with bias current 0.1 nA (fig 6 Traub et al 2005)

  SpinyStellate =	1000
  TuftedIB = 0
  TuftedRS = 0
  DeepBasket = 100
  DeepAxoaxonic = 100
  DeepLTS = 100
  NontuftedRS = 500
  TCR = 100
  nRT = 100

* TODO <2012-05-14 Mon 19:52> AWS feedback
  - [X] Niraj pointed out that in stead of having spike/nospike probabilities,
    looking at the distribution of the timing might be useful.

        - Implemented PSTH in dataviz. That takes care of the distribution.

  - Upi pointed out that in path calculation we should incorporate inhibitory
    synapse: we could as well use the actual conductances, but I was reluctant
    to go for such a fine measure.
    
* <2012-06-03 Sun 00:10> Converting Ca concentration parameters : phi to B
  I am writing test code for port of the channels to new moose. When
  converting CaConc, I got confused about the conversion of phi to B
  again. Finally this is the logic for the conversion:

  MOOSE/GENESIS uses:

  d(Ca)/dt = B * Ik - Ca/tau

  where Ik is the total Ca current and all units are in SI.

  NEURON form is:

  Ca' = - phi * ica - beta * Ca

  Now, NEURON's unit system has Ca in mM, which happens to be the SI unit
  (mole/m^3). beta is just 1/tau, so we have to convert ms-1 to s-1, i.e.,
  multiply by 1e3.

  For phi, we note that 

  - ica has opposite sign convention to Ik. So the sign is resolved.
  - now,

    B * Ik = phi * ica
    => B * Ik (in A) = phi * Ik (in mA) / area (in cm2)
    => B = phi * 1e3 / area

    2012-07-20 12:15:06 (+0530) : There is an error in the above derivation:
    (B * Ik) /s = (phi * ica ) / ms
    => B * Ik * 1e3 = phi * ica

    which leaves us with B = phi / area

    But somewhere there is a missing factor of 100 as in the single
    compartment test I get correct result only if B = 2.6e7 when phi =
    2.6e5. See today's lab note for right derivation/
    
* <2012-06-18 Mon 12:14> Effect of probe
  I plotted time-to-first spike, no. of spikes till next stimulus, spiking
  frequency within first 50 ms in 3D. This showed a clear shift in time to
  first spike due to probe stimulus. But the cells 1 synapse away from
  probe-stimulated cells did not seem separable in this. 

  With back-of-the envelop calculation showed that given the population,
  almost all cells 1 synapse away from the TCR cells will be conected to one
  probed cell or another:

  If n cells of type 'pre' connect to each cell of type 'post', the total
  number of connections is

  n * # post

  The no. of possible connections is: # pre * # post

  This gives a probability of connection:

  p ~= n / # pre

  Now, if each 'pre' cell connects to m post cells, the connection probability
  is:

  p  ~= m * # pre/ (# post * # pre)

     = m / # post

  => m ~= p * #post

  Now the number of ways to pick x distinct objects out of y is:

  C(y, x)

  Thus probability of choosing x objects out of y with replacement twice such
  that there is no overlap is:

  C(y-x, x) / C(y, x)

  The probability of managing it thrice is:

  C(y-x, x) * C(y-2x, x) / C(y,x)**2

  And for n-times it will be:

  C(y-x, x) * C(y-2x) * ... * C(y - (n-1)x) / C(y, x)**(n-1)

  if (n-1) * x < y,
  
  0 otherwise.

  In my case, 

  #pre = #TCR = 100
  #post = #SpinyStellate = 240
  n = 20
  =>
  p = 20 / 100 = 0.2

  m = 0.2 * 240 = 48

  If we pick a random cell from #post population, the probability that it is
  not connected to a probe-stimulated cell is very low (??? do exact
  calculations ???)

  The cell connects to n presynaptic cells.
  
  Calculate the probability that none of those n cells belong to the probe
  stimulated set.

  if k cells are probe stimulated,

  probability that a random cell will be in that set is k / # pre

  probability that none of n cells will be in that set is:

  (1 - k/#pre)**n

  = (1 - 5/100) ** 20

  = 0.95 ** 20

  = 0.358

  Thus, ~70% of the population will be connected to some cell that is getting
  probe stimulus.

  

  
* TODO <2012-06-18 Mon 14:26> How to look at the effect of probe?

  1. Reduce connection probability

  2. Change inhibitory/excitatory balance.
* DONE <2012-06-19 Tue 11:47> What to plot?
  CLOSED: [2012-07-05 Thu 12:19]
  - State "DONE"       from "TODO"       [2012-07-05 Thu 12:28] \\
    I am done with the plots. Was not  too informative. There was a large effect of stimulus sequence (probe is always even, bg is always odd). I checked the halved network simulated for 55 s. There is a change in PSTH of the population. I am yet to correlate the synaptic path length with the spiking time/probability/frequency.
    See blogs: http://magaj.ncbs.res.in/notepal2012/blogs/subha/2012-07-04, http://magaj.ncbs.res.in/notepal2012/blogs/subha/2012-06-26, http://magaj.ncbs.res.in/notepal2012/blogs/subha/2012-06-25-0, http://magaj.ncbs.res.in/notepal2012/blogs/subha/2012-06-18 etc.
  For each cell I have gathered teh following information:

  array: t_first_spike: Time to first spike after each stimulus
  array: t_peak_spiking: Time of peak spiking rate (within a window) after each stimulus
  array: f_peak_spiking: Peak spiking rate after each stimulus
  array: f_avg: average spiking rate after each stimulus

  I can plot:

  1. distribution of each arry over stimuli, and over cells (3D)

  2. 2D plots of averages over stimuli
     t_first_spike - t_peak_spiking
     t_first_spike - f_peak_spiking
     t_first_spike - f_avg
     t_peak_spiking - f_avg
     f_peak_spiking - f_avg
* <2012-06-20 Wed 15:16> Another blunder
  I was putting all the spike times with respect to preceding stimulus in a 1D
  array but doing the analysis assuming they were in blocks corresponding to
  preceding stimulus.
* <2012-06-21 Thu 12:12> Average spiking seems constant for bg only. Another bug?
* <2012-07-13 Fri 09:57> Check reproducibility of simulation
  While I dumped the network data, I have not actually verified that I can
  reproduce a simulation from that network information. That has been pending
  and needs serious attention.
* TODO <2012-07-25 Wed> Randomized input
  I need to try delivering the stimulus at randomized times in stead
  of at regular intervals. This is because the phase of the stimulus
  with respect to synchronized spontaneous spiking seems to be
  affecting the net result of the stimulation.
* TODO <2012-07-25 Wed> Plot PSTH for individual stimuli separately
  Visibly the response is highly varied for different stimuli in a sequence,
  but these get averaged out in the combined PSTH over all stimuli.
* DONE <2012-07-25 Wed> Verify scaling of synaptic conductance.
  CLOSED: [2012-07-26 Thu 09:34]
  - State "DONE"       from "TODO"       [2012-07-26 Thu 09:34] \\
    Checked in the network files and the individual conductances are inversely proprtional to the total number of presynaptic cells.

* <2012-07-27 Fri 15:12> Principles of Computational Modeling in Neuroscience
  Sterrat, Graham, Gilies and Willshaw, Chap 9 discusses Traub model. The bias
  currents are apparently to imitate effects of drugs in the bath.
* TODO <2012-07-29 Sun 11:12> Write to McCormick
  + The synchronized firing of spiny stellate cells at ~40 ms delay
  + The role of deep pyramids that do not firing under normal conditions
* TODO <2012-07-30 Mon 15:39> Increase magnitude of ectopic inputs
  Current ectopic inputs are subthreshold and have no visible effect on the
  spiking of the pyramidal cells.
* <2012-08-03 Fri 16:54> TCM and thesis
  1. Will be good to have some result for connectivity
     - Focus on the last figure (teh population PSTH does show a slight
       increase when probe stim is applied.)
  2. Documenting the process of model building can be useful for future.
  
* DONE <2012-08-03 Fri 17:06> What is special with 20120522_152734_10937?
  CLOSED: [2012-08-03 Fri 17:11]
  - State "DONE"       [2012-08-03 Fri 17:11] \\
    When I plotted the same in
      dataviz, they appear to fire in response to the stimulus only and possibly
      the former was an artifact of lack of resolution and using crosses for the
      data points. There were usually two spikes at a time. But no bursts as
      correctly figured by the script.
  The data from this simulation show constantly spiking spiny stellates in the
  plot_first_spikes.py output. But no bursting.

* <2012-08-04 Sat 11:44> Check if spiny stellate cells can be stimulated faster
  I cannot stimulate the TCR cells with paired pulse because of their long
  refractory period. Upi asked in TCM if I could stimulate the axons instead.
  For this I shall have to check the refractory period of spiny stellate
  cells.
